{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_iris().data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(data1, data2):\n",
    "    sum = 0\n",
    "    if (len(data1) == len(data2)):\n",
    "        for x1, x2 in zip(data1, data2):\n",
    "            sum += (x1 - x2)**2\n",
    "        dist = math.sqrt(sum)\n",
    "        return dist\n",
    "    else:\n",
    "        raise Exception('Length doesn\\'t match')\n",
    "        \n",
    "def manhattan_distance(data1, data2):\n",
    "    sum = 0\n",
    "    if (len(data1) == len(data2)):\n",
    "        for x1, x2 in zip(data1, data2):\n",
    "            sum += abs(x1 - x2)\n",
    "        return sum\n",
    "    else:\n",
    "        raise Exception('Length doesn\\'t match')\n",
    "        \n",
    "def cosine_distance(data1, data2):\n",
    "    return np.dot(data1, data2) / (np.linalg.norm(data1) * np.linalg.norm(data2))\n",
    "        \n",
    "def get_distance(data1, data2, metrics):\n",
    "    if (metrics == 'euclidean'):\n",
    "        dist = euclidean_distance(data1, data2)\n",
    "    elif (metrics == 'manhattan'):\n",
    "        dist = manhattan_distance(data1, data2)\n",
    "    elif (metrics == 'cosine'):\n",
    "        dist = cosine_distance(data1, data2)\n",
    "    else:\n",
    "        raise Exception('Metrics not defined')\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance_matrix(data, metrics):\n",
    "    dist_matrix = []\n",
    "    for idx1, data1 in enumerate(data):\n",
    "        curr_dist_matrix = []\n",
    "        for idx2, data2 in enumerate(data):\n",
    "            if (idx1 > idx2):\n",
    "                curr_dist_matrix.append(dist_matrix[idx2][idx1])\n",
    "            else:\n",
    "                dist = get_distance(data1, data2, metrics)\n",
    "                curr_dist_matrix.append(dist)\n",
    "        dist_matrix.append(curr_dist_matrix)\n",
    "    return dist_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linkage Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_linkage(cluster1, cluster2, dist_matrix):\n",
    "    max_dist = 0\n",
    "    for v1 in cluster1:\n",
    "        for v2 in cluster2:\n",
    "            if (max_dist < dist_matrix[v1][v2]):\n",
    "                max_dist = dist_matrix[v1][v2]\n",
    "    return max_dist\n",
    "\n",
    "def single_linkage(cluster1, cluster2, dist_matrix):\n",
    "    min_dist = None\n",
    "    for v1 in cluster1:\n",
    "        for v2 in cluster2:\n",
    "            if (min_dist is None) or (min_dist > dist_matrix[v1][v2]):\n",
    "                min_dist = dist_matrix[v1][v2]\n",
    "    return min_dist\n",
    "\n",
    "def average_linkage(cluster1, cluster2, dist_matrix):\n",
    "    sum_dist = 0\n",
    "    count_dist = 0\n",
    "    for v1 in cluster1:\n",
    "        for v2 in cluster2:\n",
    "            sum_dist += dist_matrix[v1][v2]\n",
    "            count_dist += 1\n",
    "    return float(sum_dist)/float(count_dist)\n",
    "\n",
    "def group_average_linkage(cluster1, cluster2, data, distance):\n",
    "    data1 = [data[i] for i in cluster1]\n",
    "    data2 = [data[i] for i in cluster2]\n",
    "    \n",
    "    avg1 = np.mean(data1, axis = 0)\n",
    "    avg2 = np.mean(data2, axis = 0)\n",
    "    \n",
    "    return get_distance(avg1, avg2, distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_used = 'cosine'\n",
    "data_used = data[:50]\n",
    "dist_matrix = calculate_distance_matrix(data_used, metrics_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7, 40, 12, 43, 8, 42, 36, 24, 22, 41, 2, 11, 1, 15], [10, 5, 31, 47, 49, 21, 37, 13, 29], [27, 16, 30, 35, 46, 18, 48, 9, 14, 44], [39, 6, 34, 0, 26, 38, 19, 20, 17, 25, 32, 4, 45, 3, 28, 23, 33]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 0, 0, 3, 3, 1, 3, 0, 0, 2, 1, 0, 0, 1, 2, 0, 2, 3, 2, 3, 3, 1,\n",
       "       0, 3, 0, 3, 3, 2, 3, 1, 2, 1, 3, 3, 3, 2, 0, 1, 3, 3, 0, 0, 0, 0,\n",
       "       2, 3, 2, 1, 2, 1], dtype=int8)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters = [[i] for i, c in enumerate(data_used)]\n",
    "n_clusters = 4\n",
    "linkage = 'complete'\n",
    "\n",
    "while(len(clusters) > n_clusters):\n",
    "    min_dist = None\n",
    "    merge_pair = (0, 0)\n",
    "    for idx1, c1 in enumerate(clusters):\n",
    "        for idx2, c2 in enumerate(clusters[(idx1 + 1) :]):\n",
    "            if (linkage == 'single'):\n",
    "                dist = single_linkage(c1, c2, dist_matrix)\n",
    "            elif (linkage == 'complete'):\n",
    "                dist = complete_linkage(c1, c2, dist_matrix)\n",
    "            elif (linkage == 'average'):\n",
    "                dist = average_linkage(c1, c2, dist_matrix)\n",
    "            elif (linkage == 'average_group'):\n",
    "                dist = group_average_linkage(c1, c2, data_used, metrics_used)\n",
    "            else:\n",
    "                raise Exception('Linkage not defined')\n",
    "            if (min_dist == None) or (dist < min_dist):\n",
    "                min_dist = dist\n",
    "                merge_pair = (idx1, idx1 + 1 + idx2)\n",
    "    \n",
    "    result_cluster = []\n",
    "    for idx, c in enumerate(clusters):\n",
    "        if idx not in merge_pair:\n",
    "            result_cluster.append(c)\n",
    "    \n",
    "    result_cluster.append(clusters[merge_pair[0]] + clusters[merge_pair[1]])\n",
    "    \n",
    "    clusters = result_cluster\n",
    "\n",
    "print(clusters)\n",
    "result_per_item = np.zeros(len(data_used), dtype= np.int8)\n",
    "for idx, clust in enumerate(clusters):\n",
    "    result_per_item[clust] = idx\n",
    "\n",
    "result_per_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparation with sklearn's Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-400a37f8fd34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAgglomerativeClustering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinkage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'complete'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maffinity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cosine'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "cls = AgglomerativeClustering(n_clusters= 4, linkage='complete', affinity='cosine')\n",
    "cls.fit_predict(data[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class tes_AgglomerativeClustering:\n",
    "    \n",
    "    n_clusters = 2\n",
    "    linkage = 'complete'\n",
    "    metrics = 'euclidean'\n",
    "    \n",
    "    available_metrics = ['euclidean', 'manhattan', 'cosine']\n",
    "    available_linkage = ['complete', 'single', 'group_average', 'average']\n",
    "    \n",
    "    def __init__(self, n_clusters=n_clusters, linkage=linkage, metrics=metrics):\n",
    "        \n",
    "        if n_clusters <= 0:\n",
    "            raise Exception('n_clusters must be higher than 0')\n",
    "        if metrics not in self.available_metrics:\n",
    "            raise Exception('No metric ' + str(metrics))\n",
    "        if linkage not in self.available_linkage:\n",
    "            raise Exception('No linkage ' + str(linkage))\n",
    "        self.metrics = metrics\n",
    "        self.n_clusters = n_clusters\n",
    "        self.linkage = linkage\n",
    "        \n",
    "    def __euclidean_distance(self, data1, data2):\n",
    "        sum = 0\n",
    "        if (len(data1) == len(data2)):\n",
    "            for x1, x2 in zip(data1, data2):\n",
    "                sum += (x1 - x2)**2\n",
    "            dist = math.sqrt(sum)\n",
    "            return dist\n",
    "        else:\n",
    "            raise Exception('Length doesn\\'t match')\n",
    "\n",
    "    def __manhattan_distance(self, data1, data2):\n",
    "        sum = 0\n",
    "        if (len(data1) == len(data2)):\n",
    "            for x1, x2 in zip(data1, data2):\n",
    "                sum += abs(x1 - x2)\n",
    "            return sum\n",
    "        else:\n",
    "            raise Exception('Length doesn\\'t match')\n",
    "            \n",
    "    def __cosine_distance(self, data1, data2):\n",
    "        return np.dot(data1, data2) / (np.linalg.norm(data1) * np.linalg.norm(data2))\n",
    "\n",
    "    def __get_distance(self, data1, data2, metrics):\n",
    "        if (metrics == 'euclidean'):\n",
    "            dist = self.__euclidean_distance(data1, data2)\n",
    "        elif (metrics == 'manhattan'):\n",
    "            dist = self.__manhattan_distance(data1, data2)\n",
    "        elif (metrics == 'cosine'):\n",
    "            dist = self.__cosine_distance(data1, data2)\n",
    "        else:\n",
    "            raise Exception('Metrics not defined')\n",
    "        return dist\n",
    "    \n",
    "    def __complete_linkage(self, cluster1, cluster2, dist_matrix):\n",
    "        max_dist = 0\n",
    "        for v1 in cluster1:\n",
    "            for v2 in cluster2:\n",
    "                if (max_dist < dist_matrix[v1][v2]):\n",
    "                    max_dist = dist_matrix[v1][v2]\n",
    "        return max_dist\n",
    "\n",
    "    def __single_linkage(self, cluster1, cluster2, dist_matrix):\n",
    "        min_dist = None\n",
    "        for v1 in cluster1:\n",
    "            for v2 in cluster2:\n",
    "                if (min_dist is None) or (min_dist > dist_matrix[v1][v2]):\n",
    "                    min_dist = dist_matrix[v1][v2]\n",
    "        return min_dist\n",
    "\n",
    "    def __average_linkage(self, cluster1, cluster2, dist_matrix):\n",
    "        sum_dist = 0\n",
    "        count_dist = 0\n",
    "        for v1 in cluster1:\n",
    "            for v2 in cluster2:\n",
    "                sum_dist += dist_matrix[v1][v2]\n",
    "                count_dist += 1\n",
    "        return float(sum_dist)/float(count_dist)\n",
    "\n",
    "    def __group_average_linkage(self, cluster1, cluster2, data, distance):\n",
    "        data1 = [data[i] for i in cluster1]\n",
    "        data2 = [data[i] for i in cluster2]\n",
    "\n",
    "        avg1 = np.mean(data1, axis = 0)\n",
    "        avg2 = np.mean(data2, axis = 0)\n",
    "\n",
    "        return self.__get_distance(avg1, avg2, distance)\n",
    "    \n",
    "    def __calculate_distance_matrix(self, data, metrics):\n",
    "        dist_matrix = []\n",
    "        for idx1, data1 in enumerate(data):\n",
    "            curr_dist_matrix = []\n",
    "            for idx2, data2 in enumerate(data):\n",
    "                if (idx1 > idx2):\n",
    "                    curr_dist_matrix.append(dist_matrix[idx2][idx1])\n",
    "                else:\n",
    "                    dist = self.__get_distance(data1, data2, metrics)\n",
    "                    curr_dist_matrix.append(dist)\n",
    "            dist_matrix.append(curr_dist_matrix)\n",
    "        return dist_matrix\n",
    "        \n",
    "    def fit_predict(self, data):\n",
    "        dist_matrix = self.__calculate_distance_matrix(data, self.metrics)\n",
    "        clusters = [[i] for i, c in enumerate(data)]\n",
    "\n",
    "        while(len(clusters) > self.n_clusters):\n",
    "            min_dist = None\n",
    "            merge_pair = (0, 0)\n",
    "            for idx1, c1 in enumerate(clusters):\n",
    "                for idx2, c2 in enumerate(clusters[(idx1 + 1) :]):\n",
    "                    if (self.linkage == 'single'):\n",
    "                        dist = self.__single_linkage(c1, c2, dist_matrix)\n",
    "                    elif (self.linkage == 'complete'):\n",
    "                        dist = self.__complete_linkage(c1, c2, dist_matrix)\n",
    "                    elif (self.linkage == 'average'):\n",
    "                        dist = self.__average_linkage(c1, c2, dist_matrix)\n",
    "                    elif (self.linkage == 'average_group'):\n",
    "                        dist = self.__group_average_linkage(c1, c2, data, self.metrics)\n",
    "                    else:\n",
    "                        raise Exception('Linkage not defined')\n",
    "                    if (min_dist == None) or (dist < min_dist):\n",
    "                        min_dist = dist\n",
    "                        merge_pair = (idx1, idx1 + 1 + idx2)\n",
    "\n",
    "            result_cluster = []\n",
    "            for idx, c in enumerate(clusters):\n",
    "                if idx not in merge_pair:\n",
    "                    result_cluster.append(c)\n",
    "\n",
    "            result_cluster.append(clusters[merge_pair[0]] + clusters[merge_pair[1]])\n",
    "\n",
    "            clusters = result_cluster\n",
    "\n",
    "#         print(clusters)\n",
    "#         result_per_item = np.zeros(len(data))\n",
    "        result_per_item = np.full(len(data), 0)\n",
    "        for idx, clust in enumerate(clusters):\n",
    "            result_per_item[clust] = idx\n",
    "\n",
    "        return result_per_item"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
