{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tugas Besar I\n",
    "### IF4071 Pembelajaran Mesin\n",
    "### *Algoritma Clustering*\n",
    "--------------------------\n",
    "Kelompok:\n",
    "\n",
    "- Diki Ardian Wirasandi (13515092)\n",
    "- Irfan Ariq (13515112)\n",
    "- Pratamamia Agung Prihatmaja (13515142)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agglomerative Clustering\n",
    "------------------------------------------\n",
    "*Agglomerative clustering* merupakan suatu teknik dalam melakukan *clustering* yang menggunakan pendekatan *hierarchical*. Ide utama dari teknik ini adalah dengan melakukan penggabungan dua buah *cluster* dengan jarak terdekat pada setiap iterasi hingga diperoleh banyak *cluster* sesuai yang dikehendaki.\n",
    "\n",
    "Dalam notasi *pseudocode*, algoritma *agglomerative clustering* adalah sebagai berikut.\n",
    "\n",
    "```\n",
    "WHILE (length(clusters_now) > nb_target_cluster) DO\n",
    "    pair_merged = get_shortest_distance_pair(clusters_now)\n",
    "    merge_cluster(pair_merged)\n",
    "    update_cluster(clusters_now)\n",
    "```\n",
    "\n",
    "Terdapat beberapa pendekatan dalam menentukan pasangan *cluster* dengan jarak terdekat. Pendekatan tersebut adalah sebagai berikut.\n",
    "\n",
    "1. ***Complete linkage***. Dilakukan dengan menghitung jarak antara dua titik terjauh pada kedua *cluster*.\n",
    "![complete linkage](img/complete.png \"Complete linkage\")\n",
    "\n",
    "2. ***Single linkage***. Dilakukan dengan menghitung jarak antara dua titik terdekat pada kedua *cluster*.\n",
    "![single linkage](img/single.png \"Single linkage\")\n",
    "\n",
    "3. ***Average linkage***. Dilakukan dengan menghitung jarak rata-rata antara semua pasangan titik pada kedua cluster.\n",
    "![average linkage](img/average.png \"Average linkage\")\n",
    "\n",
    "4. ***Average-group linkage***. Dilakukan dengan menghitung jarak antara *centroid* dari kedua *cluster*.\n",
    "![average group linkage](img/average_group.png \"Average-group linkage\")\n",
    "\n",
    "Teknik penghitungan jarak juga beragam. Dalam implementasi ini, diterapkan jarak *manhattan*, *euclidean*, dan *cosine*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class AgglomerativeClustering:\n",
    "    '''\n",
    "    Kelas untuk mengakomodasi nilai metode agglomerative clustering\n",
    "    '''\n",
    "    \n",
    "    # Nilai default parameter\n",
    "    n_clusters = 2\n",
    "    linkage = 'complete'\n",
    "    metrics = 'euclidean'\n",
    "    \n",
    "    available_metrics = ['euclidean', 'manhattan', 'cosine']\n",
    "    available_linkage = ['complete', 'single', 'average_group', 'average']\n",
    "    \n",
    "    def __init__(self, n_clusters=n_clusters, linkage=linkage, metrics=metrics):\n",
    "        '''\n",
    "        Inisiasi kelas. Parameter yang dibutuhkan untuk setiap kelas diinisiasi atau diisi dengan nilai default \n",
    "        '''\n",
    "        if n_clusters <= 0:\n",
    "            raise Exception('n_clusters must be higher than 0')\n",
    "        if metrics not in self.available_metrics:\n",
    "            raise Exception('No metrics \\'' + str(metrics) + '\\'. Available metrics '+ str(self.available_metrics))\n",
    "        if linkage not in self.available_linkage:\n",
    "            raise Exception('No linkage \\'' + str(linkage) + '\\'. Available linkage '+ str(self.available_linkage))\n",
    "        self.metrics = metrics\n",
    "        self.n_clusters = n_clusters\n",
    "        self.linkage = linkage\n",
    "        \n",
    "    def __euclidean_distance(self, data1, data2):\n",
    "        '''\n",
    "        Fungsi untuk menghitung euclidean distance di antara dua vector dengan panjang yang sama\n",
    "        '''\n",
    "        sum = 0\n",
    "        if (len(data1) == len(data2)):\n",
    "            for x1, x2 in zip(data1, data2):\n",
    "                sum += (x1 - x2)**2\n",
    "            dist = math.sqrt(sum)\n",
    "            return dist\n",
    "        else:\n",
    "            raise Exception('Length doesn\\'t match')\n",
    "\n",
    "    def __manhattan_distance(self, data1, data2):\n",
    "        '''\n",
    "        Fungsi untuk menghitung manhattan distance di antara dua vector dengan panjang yang sama\n",
    "        '''\n",
    "        sum = 0\n",
    "        if (len(data1) == len(data2)):\n",
    "            for x1, x2 in zip(data1, data2):\n",
    "                sum += abs(x1 - x2)\n",
    "            return sum\n",
    "        else:\n",
    "            raise Exception('Length doesn\\'t match')\n",
    "            \n",
    "    def __cosine_distance(self, data1, data2):\n",
    "        '''\n",
    "        Fungsi untuk menghitung cosine distance di antara dua vector dengan panjang yang sama\n",
    "        '''\n",
    "        return np.dot(data1, data2) / (np.linalg.norm(data1) * np.linalg.norm(data2))\n",
    "\n",
    "    def __get_distance(self, data1, data2, metrics):\n",
    "        '''\n",
    "        Fungsi untuk menghitung jarak dua vector dengan metric pengukuran jarak yang telah ditentukan\n",
    "        '''\n",
    "        if (metrics == 'euclidean'):\n",
    "            dist = self.__euclidean_distance(data1, data2)\n",
    "        elif (metrics == 'manhattan'):\n",
    "            dist = self.__manhattan_distance(data1, data2)\n",
    "        elif (metrics == 'cosine'):\n",
    "            dist = self.__cosine_distance(data1, data2)\n",
    "        else:\n",
    "            raise Exception('Metrics not defined')\n",
    "        return dist\n",
    "    \n",
    "    def __complete_linkage(self, cluster1, cluster2, dist_matrix):\n",
    "        '''\n",
    "        Fungsi untuk menghitung jarak antara dua cluster dengan pendekatan complete linkage\n",
    "        '''\n",
    "        max_dist = 0\n",
    "        for v1 in cluster1:\n",
    "            for v2 in cluster2:\n",
    "                if (max_dist < dist_matrix[v1][v2]):\n",
    "                    max_dist = dist_matrix[v1][v2]\n",
    "        return max_dist\n",
    "\n",
    "    def __single_linkage(self, cluster1, cluster2, dist_matrix):\n",
    "        '''\n",
    "        Fungsi untuk menghitung jarak antara dua cluster dengan pendekatan single linkage\n",
    "        '''\n",
    "        min_dist = None\n",
    "        for v1 in cluster1:\n",
    "            for v2 in cluster2:\n",
    "                if (min_dist is None) or (min_dist > dist_matrix[v1][v2]):\n",
    "                    min_dist = dist_matrix[v1][v2]\n",
    "        return min_dist\n",
    "\n",
    "    def __average_linkage(self, cluster1, cluster2, dist_matrix):\n",
    "        '''\n",
    "        Fungsi untuk menghitung jarak antara dua cluster dengan pendekatan average linkage\n",
    "        '''\n",
    "        sum_dist = 0\n",
    "        count_dist = 0\n",
    "        for v1 in cluster1:\n",
    "            for v2 in cluster2:\n",
    "                sum_dist += dist_matrix[v1][v2]\n",
    "                count_dist += 1\n",
    "        return float(sum_dist)/float(count_dist)\n",
    "\n",
    "    def __group_average_linkage(self, cluster1, cluster2, data, distance):\n",
    "        '''\n",
    "        Fungsi untuk menghitung jarak antara dua cluster dengan pendekatan average group linkage\n",
    "        '''\n",
    "        data1 = [data[i] for i in cluster1]\n",
    "        data2 = [data[i] for i in cluster2]\n",
    "\n",
    "        avg1 = np.mean(data1, axis = 0)\n",
    "        avg2 = np.mean(data2, axis = 0)\n",
    "\n",
    "        return self.__get_distance(avg1, avg2, distance)\n",
    "    \n",
    "    def __calculate_distance_matrix(self, data, metrics):\n",
    "        '''\n",
    "        Fungsi untuk menghitung distance matrix untuk semua pasangan vector di dalam data\n",
    "        '''\n",
    "        dist_matrix = []\n",
    "        for idx1, data1 in enumerate(data):\n",
    "            curr_dist_matrix = []\n",
    "            for idx2, data2 in enumerate(data):\n",
    "                if (idx1 > idx2):\n",
    "                    curr_dist_matrix.append(dist_matrix[idx2][idx1])\n",
    "                else:\n",
    "                    dist = self.__get_distance(data1, data2, metrics)\n",
    "                    curr_dist_matrix.append(dist)\n",
    "            dist_matrix.append(curr_dist_matrix)\n",
    "        return dist_matrix\n",
    "        \n",
    "    def fit_predict(self, data):\n",
    "        '''\n",
    "        Fungsi untuk melakukan clustering secara agglomerative\n",
    "        '''\n",
    "        \n",
    "        # preprocessing distance matrix\n",
    "        if (self.linkage != 'average_group'):\n",
    "            dist_matrix = self.__calculate_distance_matrix(data, self.metrics)\n",
    "        # inisiasi cluster dengan satu elemen per cluster awal \n",
    "        clusters = [[i] for i, c in enumerate(data)]\n",
    "\n",
    "        # melakukan iterasi hingga diperoleh jumlah cluster sesuai yang dikehendaki\n",
    "        while(len(clusters) > self.n_clusters):\n",
    "            min_dist = None\n",
    "            merge_pair = (0, 0)\n",
    "            \n",
    "            # mencari cluster dengan jarak terdekat untuk di-merge\n",
    "            for idx1, c1 in enumerate(clusters):\n",
    "                for idx2, c2 in enumerate(clusters[(idx1 + 1) :]):\n",
    "                    if (self.linkage == 'single'):\n",
    "                        dist = self.__single_linkage(c1, c2, dist_matrix)\n",
    "                    elif (self.linkage == 'complete'):\n",
    "                        dist = self.__complete_linkage(c1, c2, dist_matrix)\n",
    "                    elif (self.linkage == 'average'):\n",
    "                        dist = self.__average_linkage(c1, c2, dist_matrix)\n",
    "                    elif (self.linkage == 'average_group'):\n",
    "                        dist = self.__group_average_linkage(c1, c2, data, self.metrics)\n",
    "                    else:\n",
    "                        raise Exception('Linkage not defined')\n",
    "                    if (min_dist == None) or (dist < min_dist):\n",
    "                        min_dist = dist\n",
    "                        merge_pair = (idx1, idx1 + 1 + idx2)\n",
    "            \n",
    "            # merge pasangan cluster dengan jarak terdekat\n",
    "            result_cluster = []\n",
    "            for idx, c in enumerate(clusters):\n",
    "                if idx not in merge_pair:\n",
    "                    result_cluster.append(c)\n",
    "\n",
    "            result_cluster.append(clusters[merge_pair[0]] + clusters[merge_pair[1]])\n",
    "\n",
    "            clusters = result_cluster\n",
    "\n",
    "        # menampilkan hasil clustering\n",
    "        result_per_item = np.full(len(data), 0)\n",
    "        for idx, clust in enumerate(clusters):\n",
    "            result_per_item[clust] = idx\n",
    "\n",
    "        return result_per_item\n",
    "    \n",
    "    '''\n",
    "    Getter untuk parameter\n",
    "    '''\n",
    "    def get_n_cluster(self):\n",
    "        return self.n_clusters\n",
    "    \n",
    "    def get_linkage(self):\n",
    "        return self.linkage\n",
    "    \n",
    "    def get_metrics(self):\n",
    "        return self.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "Berikut adalah eksperimen yang dilakukan untuk melakukan *clustering* terhadap *dataset* iris. Digunakan *euclidean distance* dan berbagai variasi perhitungan *linkage* antara dua cluster untuk menerapkan metode *agglomerative clustering*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def purity(cluster_pred, label):\n",
    "    data_per_cluster = [[] for i in range(len(set(cluster_pred)))]\n",
    "    for i,x in enumerate(cluster_pred):\n",
    "        data_per_cluster[x].append(label[i])\n",
    "\n",
    "    sum = 0\n",
    "    for clust in data_per_cluster:\n",
    "        sum += stats.mode(clust)[1][0]\n",
    "\n",
    "    return sum/len(cluster_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "data = iris.data\n",
    "label = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering dengan Complete Linkage\n",
    "\n",
    "Pada percobaan ini, digunakan pendekatan *complete linkage* untuk menghitung jarak antar pasangan cluster. Hasil clustering dan *purity*-nya dapat dilihat pada *output* dari eksekusi *code*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Time taken: 0.7341616153717041 s ----\n",
      "Cluster prediction:\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 0 2 0 2 0 2 0 0 0 0 2 0 2 0 0 2 0 2 0 2 2\n",
      " 2 2 2 2 2 0 0 0 0 2 0 2 2 2 0 0 0 2 0 0 0 0 0 2 0 0 2 2 2 2 2 2 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "Purity: 0.84\n"
     ]
    }
   ],
   "source": [
    "aglo = AgglomerativeClustering(n_clusters=3, linkage='complete', metrics='euclidean')\n",
    "start = time.time()\n",
    "pred = aglo.fit_predict(data)\n",
    "\n",
    "print(\"---- Time taken: {} s ----\".format(time.time() - start))\n",
    "print(\"Cluster prediction:\")\n",
    "print(pred)\n",
    "print(\"Purity: {}\".format(purity(pred, label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering dengan Single Linkage\n",
    "\n",
    "Pada percobaan ini, digunakan pendekatan *single linkage* untuk menghitung jarak antar pasangan cluster. Hasil clustering dan *purity*-nya dapat dilihat pada *output* dari eksekusi *code*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Time taken: 0.6534392833709717 s ----\n",
      "Cluster prediction:\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "Purity: 0.68\n"
     ]
    }
   ],
   "source": [
    "aglo = AgglomerativeClustering(n_clusters=3, linkage='single', metrics='euclidean')\n",
    "start = time.time()\n",
    "pred = aglo.fit_predict(data)\n",
    "\n",
    "print(\"---- Time taken: {} s ----\".format(time.time() - start))\n",
    "print(\"Cluster prediction:\")\n",
    "print(pred)\n",
    "print(\"Purity: {}\".format(purity(pred, label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering dengan Average Linkage\n",
    "\n",
    "Pada percobaan ini, digunakan pendekatan *complete linkage* untuk menghitung jarak antar pasangan cluster. Hasil clustering dan *purity*-nya dapat dilihat pada *output* dari eksekusi *code*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Time taken: 1.1986215114593506 s ----\n",
      "Cluster prediction:\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 1 1 1 1 2 1 1 1 1\n",
      " 1 1 2 2 1 1 1 1 2 1 2 1 2 1 1 2 2 1 1 1 1 1 2 1 1 1 1 2 1 1 1 2 1 1 1 2 1\n",
      " 1 2]\n",
      "Purity: 0.9066666666666666\n"
     ]
    }
   ],
   "source": [
    "aglo = AgglomerativeClustering(n_clusters=3, linkage='average', metrics='euclidean')\n",
    "start = time.time()\n",
    "pred = aglo.fit_predict(data)\n",
    "\n",
    "print(\"---- Time taken: {} s ----\".format(time.time() - start))\n",
    "print(\"Cluster prediction:\")\n",
    "print(pred)\n",
    "print(\"Purity: {}\".format(purity(pred, label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering dengan Average-group Linkage\n",
    "\n",
    "Pada percobaan ini, digunakan pendekatan *average-group linkage* untuk menghitung jarak antar pasangan cluster. Hasil clustering dan *purity*-nya dapat dilihat pada *output* dari eksekusi *code*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Time taken: 43.254955530166626 s ----\n",
      "Cluster prediction:\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 0 0 0 0 2 0 0 0 0\n",
      " 0 0 2 2 0 0 0 0 2 0 2 0 2 0 0 2 2 0 0 0 0 0 2 0 0 0 0 2 0 0 0 2 0 0 0 2 0\n",
      " 0 2]\n",
      "Purity: 0.9066666666666666\n"
     ]
    }
   ],
   "source": [
    "aglo = AgglomerativeClustering(n_clusters=3, linkage='average_group', metrics='euclidean')\n",
    "start = time.time()\n",
    "pred = aglo.fit_predict(data)\n",
    "\n",
    "print(\"---- Time taken: {} s ----\".format(time.time() - start))\n",
    "print(\"Cluster prediction:\")\n",
    "print(pred)\n",
    "print(\"Purity: {}\".format(purity(pred, label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hasil dan Analisis\n",
    "\n",
    "Dari keempat eksperimen di atas, dapat ditarik kesimpulan bahwa untuk dataset iris, metode *agglomerative* dapat diterapkan untuk melakukan *clustering*. Penggunaan teknik *average linkage* dan *average-group linkage* untuk menghitung jarak antara dua cluster menghasilkan *cluster* dengan *purity* tertinggi, yaitu 0.9067. Namun, *average-group linkage* membutuhkan waktu eksekusi yang lebih lama dibandingkan *average linkage*. Hal ini dikarenakan teknik *average-group linkage* tidak dapat menggunakan hasil *preprocessing distance matrix* sehingga perlu dilakukan komputasi ulang dalam menghitung jarak antara dua *cluster* ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN\n",
    "----------------------------\n",
    "\n",
    "DBSCAN merupakan salah satu algoritma clustering yang mengelompokkan data berdasarkan kedekatannya dengan data lain. Data yang dianggap dekat akan dijadikan satu kelompok. Data dianggap dekat dan disebut bertetangga dengan data lainnya apabila jaraknya kurang dari smaa dengan nilai tertentu. Nilai tersebut disebut `epsilon`.\n",
    "\n",
    "Pada DBSCAN satu *instance* data dapat dikategorikan menjadi `core_point`, `border_point`, atau `noise_data`/outlier. Sebuah data disebut `core_point` apabila memiliki jumlah tetangganya lebih dari sama dengan nilai tertentu. Nilai tersebut disebut `min_pts`. Sebuah data dikatakan `border_point` apabila jumlah tetangganya tidak lebih dari `min_pts` namun memiliki tetangga yang merupakan `core_point`. Sedangkan `noise_data` atau outlier adalah data yang jumlah tetangganya tidak lebih dari `min_pts` dan tidak bertetangga dengan `border_point`. \n",
    "\n",
    "Setiap `core_point` dan tetangganya (baik itu `core_point` atau pun `border_point`) akan menjadi satu cluster yang sama. `noise_data` atau outlier merupakan data yang tidak memiliki cluster. \n",
    "\n",
    "Ilustrasi: \n",
    "![DBSCAN](img/dbscan.png \"Ilustrasi DBSCAN\")\n",
    "\n",
    "Pada gambar diatas, titik yang berwarna merah merupakan `core_point`, titik yang berwarna kuning merupakan `border_point` dan titik yang berwarna biru merupakan `noise_data` atau outlier.\n",
    "\n",
    "Perhitungan jarak yang dapat digunakan pada implemetasi DBSCAN ini ada dua macam yaitu jarak euclidean dan jarak manhtattan.\n",
    "\n",
    "Berikut ini merupakan pseudocode dari DBSCAN:\n",
    "\n",
    "```\n",
    "DBSCAN(data, eps, min_pts):\n",
    "    curr_label = 0\n",
    "    for data_i in data:\n",
    "        if data_i is core_point and not yet labelled:\n",
    "            label = curr_label\n",
    "            cluster(data_i) = label\n",
    "            neighbour_stack = [neighbour(data_i)]\n",
    "            while neighbour_stack is not empty:\n",
    "                neighbour_data_i = neighbour_stack.pop\n",
    "                if neighbour_data_i not yet labelled:\n",
    "                    cluster(neighbour_data_i) = label\n",
    "                    if neighbour_data_i is core point:\n",
    "                        neighbour_stack,push(neighbour(neighbour_data_i))\n",
    "           curr_label += 1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import math\n",
    "\n",
    "class tes_DBSCAN:\n",
    "    \n",
    "    UNLABELLED_DATA = -1\n",
    "    \n",
    "    n_clusters = None\n",
    "    result = None\n",
    "        \n",
    "    metrics = 'euclidean'    \n",
    "    eps = 0.5\n",
    "    min_pts = 5\n",
    "    available_metrics = ['euclidean', 'manhattan']\n",
    "\n",
    "    def __init__ (self, min_pts=min_pts, eps=eps, metrics=metrics):\n",
    "        '''\n",
    "        Inisiasi kelas dengan min_pts dan epsilon\n",
    "        '''\n",
    "        if eps <= 0:\n",
    "            raise Exception('eps must be higher than 0')\n",
    "        if min_pts <= 0:\n",
    "            raise Exception('min_pts must be higher than 0')\n",
    "        if metrics not in self.available_metrics:\n",
    "            raise Exception('No metrics \\'' + str(metrics) + '\\'. Available metrics '+ str(self.available_metrics))\n",
    "            \n",
    "        self.min_pts = min_pts\n",
    "        self.eps = eps\n",
    "        self.metrics=metrics\n",
    "        \n",
    "    def __euclidean_distance(self, point_a, point_b):\n",
    "        '''\n",
    "        Fungsi untuk menghitung euclidean distance\n",
    "        '''\n",
    "        dist = 0\n",
    "        for a, b in zip(point_a, point_b):\n",
    "            dist += (a - b) * (a - b)\n",
    "        return np.sqrt(dist)\n",
    "\n",
    "    def __manhattan_distance(self, point_a, point_b):\n",
    "        '''\n",
    "        Fungsi untuk menghitung manhattan distance \n",
    "        '''\n",
    "        dist = 0\n",
    "        for a, b in zip(point_a, point_b):\n",
    "            dist += abs(a - b)\n",
    "        return dist\n",
    "    \n",
    "    def __distance(self, point_a, point_b, metrics=metrics):\n",
    "        '''\n",
    "        Fungsi untuk mencari jarak berdasarkan metricsnya\n",
    "        '''\n",
    "        if len(point_a) == len(point_b):\n",
    "            if metrics == 'euclidean':\n",
    "                return self.__euclidean_distance(point_a, point_b)\n",
    "            if metrics == 'manhattan':\n",
    "                return self.__manhattan_distance(point_a, point_b)\n",
    "        else:\n",
    "            raise Exception(\"feature length doesn't same\")\n",
    "    \n",
    "    def fit_predict(self, data):\n",
    "        '''\n",
    "        Fungsi untuk mengelompolkkan data\n",
    "        '''\n",
    "        size_data = len(data)\n",
    "        \n",
    "        # generate all neighbours \n",
    "        neighbours = []\n",
    "        for i in range(size_data):\n",
    "            neighbour_i = []\n",
    "            for j in range(size_data):\n",
    "                if self.__distance(data[i], data[j], self.metrics) <= self.eps:\n",
    "                    neighbour_i.append(j)\n",
    "            neighbours.append(neighbour_i)\n",
    "        \n",
    "        # initialize label\n",
    "        self.result = np.full((size_data), self.UNLABELLED_DATA)\n",
    "        \n",
    "        # giving label to data\n",
    "        curr_label = 0\n",
    "        for i in range(size_data):\n",
    "            # if neighbours > min_pts (data_i is core points) and not yet labelled, then give label \n",
    "            if len(neighbours[i]) >= self.min_pts and self.result[i] == self.UNLABELLED_DATA: \n",
    "                label = curr_label\n",
    "                # giving label to all neighbours\n",
    "                neighbours_i = [i]\n",
    "                while len(neighbours_i) > 0:\n",
    "                    neigh_i = neighbours_i.pop()\n",
    "                    # if not yet labelled then give label to data and the neighbours\n",
    "                    if self.result[neigh_i] == self.UNLABELLED_DATA:\n",
    "                        self.result[neigh_i] = label\n",
    "                        # if neigh_i is core point, then give label to the neighbour\n",
    "                        if len(neighbours[neigh_i]) >= self.min_pts:\n",
    "                            neighbours_i += neighbours[neigh_i]\n",
    "                curr_label += 1\n",
    "        \n",
    "        self.n_clusters = curr_label           \n",
    "        return self.result\n",
    "    \n",
    "    def get_n_clusters(self):\n",
    "        if self.n_clusters is None:\n",
    "            print(\"No data\")\n",
    "        else:\n",
    "            return self.n_clusters\n",
    "    \n",
    "    def get_epsilon(self):\n",
    "        return self.eps\n",
    "\n",
    "    def get_metrics(self):\n",
    "        return self.metrics\n",
    "    \n",
    "    def get_min_pts(self):\n",
    "        return self.min_pts\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "\n",
    "Berikut ini merupakan hasil eksperimen implementasi DBSCAN untuk clustering data iris menggunakan *euclidean disntance*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "data = iris.data\n",
    "label = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def purity(cluster_pred, label):\n",
    "    outlier = False\n",
    "    size_data = len(cluster_pred)\n",
    "    \n",
    "    data_per_cluster = [[] for i in range(len(set(cluster_pred)))]\n",
    "    for i,x in enumerate(cluster_pred):\n",
    "        if x == -1:\n",
    "            outlier = True\n",
    "        data_per_cluster[x].append(label[i])\n",
    "\n",
    "    sum = 0\n",
    "    for clust in data_per_cluster:\n",
    "        sum += stats.mode(clust)[1][0]\n",
    "    \n",
    "    if outlier:\n",
    "        sum -= stats.mode(clust)[1][0]\n",
    "        size_data -= len(clust)\n",
    "\n",
    "    return sum/size_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Time taken: 0.2908132076263428 s ----\n",
      "---- Cluster: 3 ----\n",
      "Cluster prediction:\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1  0  0  0  0  0  0\n",
      "  0  0  1  1  1  1  1  1  1  2  1  1  2  1  1  1  1  1  1  1 -1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 -1  1  1  1  1  1  2  1  1\n",
      "  1  1  2  1  1  1  1  1  1 -1 -1  1 -1 -1  1  1  1  1  1  1  1 -1 -1  1\n",
      "  1  1 -1  1  1  1  1  1  1  1  1 -1  1  1 -1 -1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1]\n",
      "Purity: 0.708029197080292\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "dbscan = tes_DBSCAN(eps=0.5, min_pts=4, metrics='euclidean')\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "pred = dbscan.fit_predict(data)\n",
    "\n",
    "print(\"---- Time taken: {} s ----\".format(time.time() - start))\n",
    "print(\"---- Cluster: {} ----\".format(dbscan.get_n_clusters()))\n",
    "print(\"Cluster prediction:\")\n",
    "print(pred)\n",
    "print(\"Purity: {}\".format(purity(pred, label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Time taken: 0.24554896354675293 s ----\n",
      "---- Cluster: 2 ----\n",
      "Cluster prediction:\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1]\n",
      "Purity: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "dbscan = tes_DBSCAN(eps=1, min_pts=3, metrics='euclidean')\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "pred = dbscan.fit_predict(data)\n",
    "\n",
    "print(\"---- Time taken: {} s ----\".format(time.time() - start))\n",
    "print(\"---- Cluster: {} ----\".format(dbscan.get_n_clusters()))\n",
    "print(\"Cluster prediction:\")\n",
    "print(pred)\n",
    "print(\"Purity: {}\".format(purity(pred, label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hasil Eksperimen\n",
    "\n",
    "Dari kedua hasil eksperimen diatas, dapat dilihat bahwa DBSCAN mampu mengelompokkan data iris dalam waktu sekitar 0.2 - 0.3  detik. Namun kedua eksperimen menghasilkan nilai purity yang berbeda, hal ini dikarenakan perbedaan nilai `epsilon` dan `min_pts`. Dengan nilai `epsilon` 0.5 dan `min_pts` 4, DBSCAN menghasilkan 3 kluster dan beberapa data yang dianggap outlier. Sedangkan dengan nilai `epsilon` 1 dan `min_pts` 3, DBSCAN menghasilkan 2 kluster dan tanpa ada data yang dianggap outlier. Hal ini menunjukkan bahwa DBSCAN akan sangat bergantung terhadap kedua nilai tersebut dan ini merupakan tantangan dalam menggunakan DBSCAN."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
