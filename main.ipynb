{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import math\n",
    "\n",
    "class DBSCAN:\n",
    "    \n",
    "    UNLABELLED_DATA = -1\n",
    "        \n",
    "    metrics = 'euclidean'    \n",
    "    eps = 0.5\n",
    "    min_pts = 5\n",
    "    available_metrics = ['euclidean', 'manhattan']\n",
    "\n",
    "    def __init__ (self, min_pts=min_pts, eps=eps, metrics=metrics):\n",
    "        \n",
    "        if eps <= 0:\n",
    "            raise Exception('eps must be higher than 0')\n",
    "        if min_pts <= 0:\n",
    "            raise Exception('min_pts must be higher than 0')\n",
    "        if metrics not in self.available_metrics:\n",
    "            raise Exception('No metrics \\'' + str(metrics) + '\\'. Available metrics '+ str(self.available_metrics))\n",
    "            \n",
    "        self.min_pts = min_pts\n",
    "        self.eps = eps\n",
    "        self.metrics=metrics\n",
    "        \n",
    "    def __euclidean_distance(self, point_a, point_b):\n",
    "        dist = 0\n",
    "        for a, b in zip(point_a, point_b):\n",
    "            dist += (a - b) * (a - b)\n",
    "        return np.sqrt(dist)\n",
    "\n",
    "    def __manhattan_distance(self, point_a, point_b):\n",
    "        dist = 0\n",
    "        for a, b in zip(point_a, point_b):\n",
    "            dist += abs(a - b)\n",
    "        return dist\n",
    "    \n",
    "    def __distance(self, point_a, point_b, metrics=metrics):\n",
    "        # \n",
    "        if len(point_a) == len(point_b):\n",
    "            if metrics == 'euclidean':\n",
    "                return self.__euclidean_distance(point_a, point_b)\n",
    "            if metrics == 'manhattan':\n",
    "                return self.__manhattan_distance(point_a, point_b)\n",
    "        else:\n",
    "            raise Exception(\"feature length doesn't same\")\n",
    "    \n",
    "    def fit_predict(self, data):\n",
    "        size_data = len(data)\n",
    "        \n",
    "        # generate all neighbours \n",
    "        neighbours = []\n",
    "        for i in range(size_data):\n",
    "            neighbour_i = []\n",
    "            for j in range(size_data):\n",
    "                if self.__distance(data[i], data[j], self.metrics) <= self.eps:\n",
    "                    neighbour_i.append(j)\n",
    "            neighbours.append(neighbour_i)\n",
    "        \n",
    "        # initialize label\n",
    "        result = np.full((size_data), self.UNLABELLED_DATA)\n",
    "        \n",
    "        # giving label to data\n",
    "        curr_label = 0\n",
    "        for i in range(size_data):\n",
    "            # if neighbours > min_pts (core points) then give label \n",
    "            if len(neighbours[i]) >= self.min_pts and result[i] == self.UNLABELLED_DATA: \n",
    "                label = curr_label\n",
    "                # giving label to all neighbours\n",
    "                neighbours_i = [i]\n",
    "                while len(neighbours_i) > 0:\n",
    "                    neigh_i = neighbours_i.pop()\n",
    "                    # if not yet labelled then give label to data and the neighbours\n",
    "                    if result[neigh_i] == self.UNLABELLED_DATA:\n",
    "                        result[neigh_i] = label\n",
    "                        # if neigh_i is core point, then give label to the neighbour\n",
    "                        if len(neighbours[neigh_i]) >= self.min_pts:\n",
    "                            neighbours_i += neighbours[neigh_i]\n",
    "                curr_label += 1\n",
    "                \n",
    "        return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class AgglomerativeClustering:\n",
    "    \n",
    "    n_clusters = 2\n",
    "    linkage = 'complete'\n",
    "    metrics = 'euclidean'\n",
    "    \n",
    "    available_metrics = ['euclidean', 'manhattan', 'cosine']\n",
    "    available_linkage = ['complete', 'single', 'group_average', 'average']\n",
    "    \n",
    "    def __init__(self, n_clusters=n_clusters, linkage=linkage, metrics=metrics):\n",
    "        \n",
    "        if n_clusters <= 0:\n",
    "            raise Exception('n_clusters must be higher than 0')\n",
    "        if metrics not in self.available_metrics:\n",
    "            raise Exception('No metrics \\'' + str(metrics) + '\\'. Available metrics '+ str(self.available_metrics))\n",
    "        if linkage not in self.available_linkage:\n",
    "            raise Exception('No linkage \\'' + str(linkage) + '\\'. Available linkage '+ str(self.available_linkage))\n",
    "        self.metrics = metrics\n",
    "        self.n_clusters = n_clusters\n",
    "        self.linkage = linkage\n",
    "        \n",
    "    def __euclidean_distance(self, data1, data2):\n",
    "        sum = 0\n",
    "        if (len(data1) == len(data2)):\n",
    "            for x1, x2 in zip(data1, data2):\n",
    "                sum += (x1 - x2)**2\n",
    "            dist = math.sqrt(sum)\n",
    "            return dist\n",
    "        else:\n",
    "            raise Exception('Length doesn\\'t match')\n",
    "\n",
    "    def __manhattan_distance(self, data1, data2):\n",
    "        sum = 0\n",
    "        if (len(data1) == len(data2)):\n",
    "            for x1, x2 in zip(data1, data2):\n",
    "                sum += abs(x1 - x2)\n",
    "            return sum\n",
    "        else:\n",
    "            raise Exception('Length doesn\\'t match')\n",
    "            \n",
    "    def __cosine_distance(self, data1, data2):\n",
    "        return np.dot(data1, data2) / (np.linalg.norm(data1) * np.linalg.norm(data2))\n",
    "\n",
    "    def __get_distance(self, data1, data2, metrics):\n",
    "        if (metrics == 'euclidean'):\n",
    "            dist = self.__euclidean_distance(data1, data2)\n",
    "        elif (metrics == 'manhattan'):\n",
    "            dist = self.__manhattan_distance(data1, data2)\n",
    "        elif (metrics == 'cosine'):\n",
    "            dist = self.__cosine_distance(data1, data2)\n",
    "        else:\n",
    "            raise Exception('Metrics not defined')\n",
    "        return dist\n",
    "    \n",
    "    def __complete_linkage(self, cluster1, cluster2, dist_matrix):\n",
    "        max_dist = 0\n",
    "        for v1 in cluster1:\n",
    "            for v2 in cluster2:\n",
    "                if (max_dist < dist_matrix[v1][v2]):\n",
    "                    max_dist = dist_matrix[v1][v2]\n",
    "        return max_dist\n",
    "\n",
    "    def __single_linkage(self, cluster1, cluster2, dist_matrix):\n",
    "        min_dist = None\n",
    "        for v1 in cluster1:\n",
    "            for v2 in cluster2:\n",
    "                if (min_dist is None) or (min_dist > dist_matrix[v1][v2]):\n",
    "                    min_dist = dist_matrix[v1][v2]\n",
    "        return min_dist\n",
    "\n",
    "    def __average_linkage(self, cluster1, cluster2, dist_matrix):\n",
    "        sum_dist = 0\n",
    "        count_dist = 0\n",
    "        for v1 in cluster1:\n",
    "            for v2 in cluster2:\n",
    "                sum_dist += dist_matrix[v1][v2]\n",
    "                count_dist += 1\n",
    "        return float(sum_dist)/float(count_dist)\n",
    "\n",
    "    def __group_average_linkage(self, cluster1, cluster2, data, distance):\n",
    "        data1 = [data[i] for i in cluster1]\n",
    "        data2 = [data[i] for i in cluster2]\n",
    "\n",
    "        avg1 = np.mean(data1, axis = 0)\n",
    "        avg2 = np.mean(data2, axis = 0)\n",
    "\n",
    "        return self.__get_distance(avg1, avg2, distance)\n",
    "    \n",
    "    def __calculate_distance_matrix(self, data, metrics):\n",
    "        dist_matrix = []\n",
    "        for idx1, data1 in enumerate(data):\n",
    "            curr_dist_matrix = []\n",
    "            for idx2, data2 in enumerate(data):\n",
    "                if (idx1 > idx2):\n",
    "                    curr_dist_matrix.append(dist_matrix[idx2][idx1])\n",
    "                else:\n",
    "                    dist = self.__get_distance(data1, data2, metrics)\n",
    "                    curr_dist_matrix.append(dist)\n",
    "            dist_matrix.append(curr_dist_matrix)\n",
    "        return dist_matrix\n",
    "        \n",
    "    def fit_predict(self, data):\n",
    "        dist_matrix = self.__calculate_distance_matrix(data, self.metrics)\n",
    "        clusters = [[i] for i, c in enumerate(data)]\n",
    "\n",
    "        while(len(clusters) > self.n_clusters):\n",
    "            min_dist = None\n",
    "            merge_pair = (0, 0)\n",
    "            for idx1, c1 in enumerate(clusters):\n",
    "                for idx2, c2 in enumerate(clusters[(idx1 + 1) :]):\n",
    "                    if (self.linkage == 'single'):\n",
    "                        dist = self.__single_linkage(c1, c2, dist_matrix)\n",
    "                    elif (self.linkage == 'complete'):\n",
    "                        dist = self.__complete_linkage(c1, c2, dist_matrix)\n",
    "                    elif (self.linkage == 'average'):\n",
    "                        dist = self.__average_linkage(c1, c2, dist_matrix)\n",
    "                    elif (self.linkage == 'average_group'):\n",
    "                        dist = self.__group_average_linkage(c1, c2, data, self.metrics)\n",
    "                    else:\n",
    "                        raise Exception('Linkage not defined')\n",
    "                    if (min_dist == None) or (dist < min_dist):\n",
    "                        min_dist = dist\n",
    "                        merge_pair = (idx1, idx1 + 1 + idx2)\n",
    "\n",
    "            result_cluster = []\n",
    "            for idx, c in enumerate(clusters):\n",
    "                if idx not in merge_pair:\n",
    "                    result_cluster.append(c)\n",
    "\n",
    "            result_cluster.append(clusters[merge_pair[0]] + clusters[merge_pair[1]])\n",
    "\n",
    "            clusters = result_cluster\n",
    "\n",
    "#         print(clusters)\n",
    "#         result_per_item = np.zeros(len(data))\n",
    "        result_per_item = np.full(len(data), 0)\n",
    "        for idx, clust in enumerate(clusters):\n",
    "            result_per_item[clust] = idx\n",
    "\n",
    "        return result_per_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
