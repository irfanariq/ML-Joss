{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_iris().data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KMeans\n",
    "------------------------------------------\n",
    "*KMeans* merupakan suatu teknik dalam melakukan *clustering* yang menggunakan pendekatan *partitioning*. Ide utama dari teknik ini adalah dengan mengelompokkan data ke K *cluster*. Penentuan *cluster* mana untuk data tertentu yaitu dengan cara menghitung jarak data tersebut dengan representasi dari *cluster* (*centroid*). Representasi dari *cluster* berupa rata-rata (*means*) dari data-data anggota *cluster* tersebut. Penghitungan jarak dengan menggunakan *euclidean distance*.\n",
    "\n",
    "![kmeans](img/kmeans.png \"KMeans Clustering\")\n",
    "\n",
    "Dalam notasi *pseudocode*, algoritma *KMeans* adalah sebagai berikut.\n",
    "\n",
    "```\n",
    "choose_initial_centroid()\n",
    "WHILE (any_change_in_cluster) DO\n",
    "    FOREACH object\n",
    "        assign_to_cluster(object)\n",
    "    FOREACH cluster\n",
    "        update_cluster_means(cluster)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "\n",
    "class KMeans:\n",
    "    '''\n",
    "    Kelas untuk mengakomodasi nilai metode agglomerative clustering\n",
    "    '''\n",
    "    # Nilai default parameter\n",
    "    n_clusters = 2\n",
    "    init = 'random'\n",
    "    max_iter = 300\n",
    "    init_val = []\n",
    "    \n",
    "    available_init = ['random', 'manual']\n",
    "    \n",
    "    def __init__(self, n_clusters=n_clusters, init=init, init_val=init_val, max_iter=max_iter):\n",
    "         '''\n",
    "        Inisiasi kelas. Parameter yang dibutuhkan untuk setiap kelas diinisiasi atau diisi dengan nilai default \n",
    "        '''\n",
    "        if n_clusters <= 0:\n",
    "            raise Exception('n_clusters must be higher than 0')\n",
    "        if init not in self.available_init:\n",
    "            raise Exception('No init method \\'' + str(init) + '\\'. Available init methods'+ str(self.available_init))\n",
    "        if (init == 'manual' and len(init_val) != n_clusters):\n",
    "            raise Exception('init_val length doesn\\'t match with n_clusters '+ str(n_clusters))\n",
    "        self.n_clusters = n_clusters\n",
    "        self.init = init\n",
    "        self.max_iter = max_iter\n",
    "        self.init_val = init_val\n",
    "    \n",
    "    def __is_in_array(self, data, arr):\n",
    "        '''\n",
    "        Fungsi helper untuk menegecek apakah data berupa array berada pada arr berupa array of array\n",
    "        '''\n",
    "        is_exist = False\n",
    "        arr_idx = 0\n",
    "        while (not is_exist and arr_idx < len(arr)):\n",
    "            is_data_equal = True\n",
    "            data_idx = 0\n",
    "            while (is_data_equal and data_idx < len(data)):\n",
    "                if (data[data_idx] != arr[arr_idx][data_idx]):\n",
    "                    is_data_equal = False\n",
    "                else:\n",
    "                    data_idx += 1\n",
    "            if is_data_equal:\n",
    "                is_exist = True\n",
    "            else:\n",
    "                arr_idx += 1\n",
    "        return is_exist\n",
    "        \n",
    "    def __euclidean_distance(self, data1, data2):\n",
    "        '''\n",
    "        Fungsi untuk menghitung euclidean distance di antara dua vector dengan panjang yang sama\n",
    "        '''\n",
    "        sum = 0\n",
    "        if (len(data1) == len(data2)):\n",
    "            for x1, x2 in zip(data1, data2):\n",
    "                sum += (x1 - x2)**2\n",
    "            dist = math.sqrt(sum)\n",
    "            return dist\n",
    "        else:\n",
    "            raise Exception('Length doesn\\'t match')\n",
    "            \n",
    "    def __get_distance(self, data1, data2):\n",
    "        '''\n",
    "        Fungsi untuk menghitung jarak dua vector\n",
    "        '''\n",
    "        return self.__euclidean_distance(data1, data2)\n",
    "        \n",
    "    def __calculate_distance_matrix(self, data, centroids):\n",
    "        '''\n",
    "        Fungsi untuk menghitung distance matrix untuk semua data dengan centroid\n",
    "        '''\n",
    "        dist_matrix = []        \n",
    "        for i in range(len(centroids)):\n",
    "            dist_curr_centroid = []\n",
    "            for j in range(len(data)):\n",
    "                dist = self.__get_distance(centroids[i], data[j])\n",
    "                dist_curr_centroid.append(dist)\n",
    "            dist_matrix.append(dist_curr_centroid)\n",
    "        \n",
    "        return dist_matrix\n",
    "    \n",
    "    def __assign_data_to_cluster(self, dist_matrix):\n",
    "        '''\n",
    "        Fungsi untuk mengelompokan data berdasarkan jarak yang diketahui\n",
    "        '''\n",
    "        cluster_of_data = []\n",
    "        for j in range(len(dist_matrix[0])):\n",
    "            cluster = 0\n",
    "            min_distance = dist_matrix[0][j]\n",
    "            for i in range(1,len(dist_matrix)):\n",
    "                if (dist_matrix[i][j] < min_distance):\n",
    "                    cluster = i\n",
    "                    min_distance = dist_matrix[i][j]\n",
    "            cluster_of_data.append(cluster)\n",
    "        return cluster_of_data\n",
    "        \n",
    "    def __get_centroids(self, data, cluster_of_data):\n",
    "        '''\n",
    "        Fungsi untuk menghitung centroid baru\n",
    "        '''\n",
    "        centroids = []\n",
    "        data_per_cluster = []\n",
    "        # inisiasi\n",
    "        for n in range(self.n_clusters):\n",
    "            data_per_cluster.append([])\n",
    "        # masukkan data ke array tiap cluster\n",
    "        for idx, data_cluster in enumerate(cluster_of_data):\n",
    "            data_per_cluster[data_cluster].append(data[idx])\n",
    "        # hitung means\n",
    "        for n in range(self.n_clusters):\n",
    "            if len(data_per_cluster[n]) > 0:\n",
    "                means_cluster = []\n",
    "                for column in range(len(data_per_cluster[n][0])):\n",
    "                    sum_column = 0\n",
    "                    for d in data_per_cluster[n]:\n",
    "                        sum_column += d[column]\n",
    "                    means_column = sum_column / len(data_per_cluster[n])\n",
    "                    means_cluster.append(means_column)\n",
    "                centroids.append(means_cluster)\n",
    "        return centroids\n",
    "        \n",
    "    def fit_predict(self, data):\n",
    "        '''\n",
    "        Fungsi untuk melakukan clustering secara agglomerative\n",
    "        '''\n",
    "        \n",
    "        cluster_of_data = []\n",
    "        \n",
    "        # initiate centroid\n",
    "        centroids = []\n",
    "        if (self.init == 'random'):\n",
    "            # cek keunikan data\n",
    "            unique_data_idx = []\n",
    "            unique_data = []\n",
    "            i = 0\n",
    "            while (len(unique_data_idx) < self.n_clusters) and (i < len(data)):\n",
    "                if not self.__is_in_array(data[i], unique_data):\n",
    "                    unique_data_idx.append(i)\n",
    "                    unique_data.append(data[i])\n",
    "                i += 1\n",
    "                \n",
    "            if (len(unique_data_idx) < self.n_clusters):\n",
    "                # jika keunikan data kurang dari n_clusters\n",
    "                for u in unique_data_idx:\n",
    "                    curr_centroid = np.copy(data[u])\n",
    "                    centroids.append(curr_centroid)\n",
    "                for i in range(self.n_clusters - len(unique_data_idx)):\n",
    "                    rand_idx = random.randint(-1,len(data)-1)\n",
    "                    # cek apakah sudah terpilih atau belum\n",
    "                    while (rand_idx in unique_data_idx):\n",
    "                        rand_idx = random.randint(-1,len(data)-1)\n",
    "                    curr_centroid = np.copy(data[rand_idx])\n",
    "                    centroids.append(curr_centroid)\n",
    "            else:\n",
    "                for i in range(self.n_clusters):\n",
    "                    rand_idx = random.randint(-1,len(data)-1)\n",
    "                    curr_centroid = np.copy(data[rand_idx])\n",
    "                    # cek apakah sudah terpilih atau belum\n",
    "                    while (self.__is_in_array(curr_centroid, centroids)):\n",
    "                        rand_idx = random.randint(-1,len(data)-1)\n",
    "                        curr_centroid = np.copy(data[rand_idx])\n",
    "                    centroids.append(curr_centroid)\n",
    "        else:\n",
    "            # self.init == 'manual'\n",
    "            centroids = self.init_val\n",
    "        \n",
    "        iteration = 1\n",
    "        is_convergen = False\n",
    "        while (not is_convergen and iteration <= self.max_iter):\n",
    "            # calculate distance all data to all centroid\n",
    "            dist_matrix = self.__calculate_distance_matrix(data, centroids)\n",
    "            # assign all data to cluster\n",
    "            new_cluster_of_data = self.__assign_data_to_cluster(dist_matrix)\n",
    "            # convergency checking\n",
    "            is_convergen = np.array_equal(cluster_of_data, new_cluster_of_data)\n",
    "            # for next iteration\n",
    "            if not is_convergen:\n",
    "                cluster_of_data = np.copy(new_cluster_of_data)\n",
    "                centroids = self.__get_centroids(data, cluster_of_data)\n",
    "                iteration += 1\n",
    "    \n",
    "        return cluster_of_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0, 3, 1, 0, 2, 1, 3, 1, 1, 2, 3, 3, 3, 0, 3, 3, 0, 0,\n",
       "       2, 0, 1, 1, 0, 0, 0, 1, 1, 0, 3, 3, 1, 1, 0, 1, 2, 0, 0, 2, 2, 0,\n",
       "       3, 1, 3, 1, 3, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = MyKMeans(n_clusters=4)\n",
    "pred_a = kmeans.fit(data[:50])\n",
    "pred_a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
