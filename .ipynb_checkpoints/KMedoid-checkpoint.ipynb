{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KMedoid (PAM)\n",
    "------------------------------------------\n",
    "*KMedoid* merupakan suatu teknik dalam melakukan *clustering* yang menggunakan pendekatan *partitioning*. Ide utama dari teknik ini adalah dengan mengelompokkan data ke K *cluster*. Penentuan *cluster* mana untuk data tertentu yaitu dengan cara menghitung jarak data tersebut dengan representasi dari *cluster* (*centroid*). Representasi dari *cluster* berupa sebuah data (*medoid*) dari data-data anggota *cluster* tersebut. Penghitungan jarak dengan menggunakan *manhattan distance*. *Medoid* akan di-update setiap iterasi dengan cara pemilihan secara random pada cluster tertentu, kemudian dihitung perubahan *error*. *Error* berupa *absolute error*, jika perubahan *error* < 0, maka iterasi akan berlanjut dan *medoid* di-update. \n",
    "\n",
    "![kmedoid](img/kmedoid.png \"KMedoid Clustering\")\n",
    "\n",
    "Dalam notasi *pseudocode*, algoritma *KMedoid* adalah sebagai berikut.\n",
    "\n",
    "```\n",
    "choose_initial_centroid()\n",
    "REPEAT\n",
    "    FOREACH object\n",
    "        assign_to_cluster(object)\n",
    "    choose_new_centroid()\n",
    "    calculate_total_error()\n",
    "    if (total_error < 0)\n",
    "        swap(old_centroid, new_centroid)\n",
    "UNTIL no_changes\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "\n",
    "class KMedoid:\n",
    "    '''\n",
    "    Kelas untuk mengakomodasi nilai metode KMedoid clustering\n",
    "    '''\n",
    "    # Nilai default parameter\n",
    "    n_clusters = 2\n",
    "    init = 'random'\n",
    "    max_iter = 300\n",
    "    init_val = []\n",
    "    randomize_cluster = 0\n",
    "    choosen_cluster = []\n",
    "    \n",
    "    available_init = ['random', 'manual']\n",
    "    \n",
    "    def __init__(self, n_clusters=n_clusters, init=init, init_val=init_val,\n",
    "                 max_iter=max_iter, randomize_cluster=randomize_cluster):\n",
    "        '''\n",
    "        Inisiasi kelas. Parameter yang dibutuhkan untuk setiap kelas diinisiasi atau diisi dengan nilai default \n",
    "        '''\n",
    "        if n_clusters <= 0:\n",
    "            raise Exception('n_clusters must be higher than 0')\n",
    "        if init not in self.available_init:\n",
    "            raise Exception('No init method \\'' + str(init) + '\\'. Available init methods'+ str(self.available_init))\n",
    "        if (init == 'manual' and len(init_val) != n_clusters):\n",
    "            raise Exception('init_val length doesn\\'t match with n_clusters '+ str(n_clusters))\n",
    "        if (n_clusters-1 < randomize_cluster) or (randomize_cluster < 0):\n",
    "            raise Exception('randomize_cluster must be between 0 and n_clusters-1')\n",
    "        self.n_clusters = n_clusters\n",
    "        self.init = init\n",
    "        self.max_iter = max_iter\n",
    "        self.init_val = init_val\n",
    "        self.randomize_cluster = randomize_cluster\n",
    "    \n",
    "    def __is_in_array(self, data, arr):\n",
    "        '''\n",
    "        Fungsi helper untuk menegecek apakah data berupa array berada pada arr berupa array of array\n",
    "        '''\n",
    "        is_exist = False\n",
    "        arr_idx = 0\n",
    "        while (not is_exist and arr_idx < len(arr)):\n",
    "            is_data_equal = True\n",
    "            data_idx = 0\n",
    "            while (is_data_equal and data_idx < len(data)):\n",
    "                if (data[data_idx] != arr[arr_idx][data_idx]):\n",
    "                    is_data_equal = False\n",
    "                else:\n",
    "                    data_idx += 1\n",
    "            if is_data_equal:\n",
    "                is_exist = True\n",
    "            else:\n",
    "                arr_idx += 1\n",
    "        return is_exist\n",
    "        \n",
    "    def __manhattan_distance(self, data1, data2):\n",
    "        '''\n",
    "        Fungsi untuk menghitung manhattan distance di antara dua vector dengan panjang yang sama\n",
    "        '''\n",
    "        sum = 0\n",
    "        if (len(data1) == len(data2)):\n",
    "            for x1, x2 in zip(data1, data2):\n",
    "                sum += abs(x1 - x2)\n",
    "            return sum\n",
    "        else:\n",
    "            raise Exception('Length doesn\\'t match')\n",
    "            \n",
    "    def __get_distance(self, data1, data2):\n",
    "        '''\n",
    "        Fungsi untuk menghitung jarak dua vector\n",
    "        '''\n",
    "        return self.__manhattan_distance(data1, data2)\n",
    "        \n",
    "    def __calculate_distance_matrix(self, data, centroids):\n",
    "        '''\n",
    "        Fungsi untuk menghitung distance matrix untuk semua data dengan centroid\n",
    "        '''\n",
    "        dist_matrix = []        \n",
    "        for i in range(len(centroids)):\n",
    "            dist_curr_centroid = []\n",
    "            for j in range(len(data)):\n",
    "                dist = self.__get_distance(centroids[i], data[j])\n",
    "                dist_curr_centroid.append(dist)\n",
    "            dist_matrix.append(dist_curr_centroid)\n",
    "        \n",
    "        return dist_matrix\n",
    "    \n",
    "    def __assign_data_to_cluster(self, dist_matrix):\n",
    "        '''\n",
    "        Fungsi untuk mengelompokan data berdasarkan jarak yang diketahui\n",
    "        '''\n",
    "        cluster_of_data = []\n",
    "        for j in range(len(dist_matrix[0])):\n",
    "            cluster = 0\n",
    "            min_distance = dist_matrix[0][j]\n",
    "            for i in range(1,len(dist_matrix)):\n",
    "                if (dist_matrix[i][j] < min_distance):\n",
    "                    cluster = i\n",
    "                    min_distance = dist_matrix[i][j]\n",
    "            cluster_of_data.append(cluster)\n",
    "        return cluster_of_data\n",
    "    \n",
    "    def __get_centroids(self, data, cluster_of_data, centroids):\n",
    "        '''\n",
    "        Fungsi untuk mendapatkan centroid baru\n",
    "        '''\n",
    "        # centroid candidate\n",
    "        data_of_randomize_cluster = []\n",
    "        for idx, data_cluster in enumerate(cluster_of_data):\n",
    "            if data_cluster == self.randomize_cluster:\n",
    "                data_of_randomize_cluster.append(data[idx])\n",
    "        \n",
    "        # choose random\n",
    "        idx = 0\n",
    "        stop = False\n",
    "        while ( not stop and idx < len(data_of_randomize_cluster)\n",
    "        ):\n",
    "            new_centroid = np.copy(data_of_randomize_cluster[idx])\n",
    "            if (\n",
    "                self.__get_distance(new_centroid, centroids[self.randomize_cluster]) == 0 or \n",
    "                self.__is_in_array(new_centroid, self.choosen_cluster)\n",
    "            ):\n",
    "                idx += 1\n",
    "            else:\n",
    "                stop = True\n",
    "        \n",
    "        if not self.__is_in_array(new_centroid, self.choosen_cluster):\n",
    "            self.choosen_cluster.append(new_centroid)\n",
    "        \n",
    "        new_centroids = np.copy(centroids)\n",
    "        new_centroids[self.randomize_cluster] = new_centroid\n",
    "        return new_centroids\n",
    "    \n",
    "    def __calculate_error(self, data, cluster_of_data, new_cluster_of_data, centroids, new_centroids):\n",
    "        '''\n",
    "        Fungsi untuk menghitung total absolute error\n",
    "        '''\n",
    "        \n",
    "        old_error = 0\n",
    "        new_error = 0\n",
    "        for n in range(self.n_clusters):\n",
    "            for idx, val in enumerate(data):\n",
    "                old_error += self.__get_distance(val, centroids[cluster_of_data[idx]])\n",
    "                new_error += self.__get_distance(val, new_centroids[new_cluster_of_data[idx]])\n",
    "        \n",
    "        return new_error-old_error\n",
    "        \n",
    "    def fit_predict(self, data):\n",
    "        '''\n",
    "        Fungsi untuk melakukan clustering secara KMedoid\n",
    "        '''\n",
    "        \n",
    "        cluster_of_data = []\n",
    "        \n",
    "        # initiate centroid\n",
    "        centroids = []\n",
    "        if (self.init == 'random'):\n",
    "            # cek keunikan data\n",
    "            unique_data_idx = []\n",
    "            unique_data = []\n",
    "            i = 0\n",
    "            while (len(unique_data_idx) < self.n_clusters) and (i < len(data)):\n",
    "                if not self.__is_in_array(data[i], unique_data):\n",
    "                    unique_data_idx.append(i)\n",
    "                    unique_data.append(data[i])\n",
    "                i += 1\n",
    "                \n",
    "            if (len(unique_data_idx) < self.n_clusters):\n",
    "                # jika keunikan data kurang dari n_clusters\n",
    "                for u in unique_data_idx:\n",
    "                    curr_centroid = np.copy(data[u])\n",
    "                    centroids.append(curr_centroid)\n",
    "                for i in range(self.n_clusters - len(unique_data_idx)):\n",
    "                    rand_idx = random.randint(-1,len(data)-1)\n",
    "                    # cek apakah sudah terpilih atau belum\n",
    "                    while (rand_idx in unique_data_idx):\n",
    "                        rand_idx = random.randint(-1,len(data)-1)\n",
    "                    curr_centroid = np.copy(data[rand_idx])\n",
    "                    centroids.append(curr_centroid)\n",
    "            else:\n",
    "                for i in range(self.n_clusters):\n",
    "                    rand_idx = random.randint(-1,len(data)-1)\n",
    "                    curr_centroid = np.copy(data[rand_idx])\n",
    "                    # cek apakah sudah terpilih atau belum\n",
    "                    while (self.__is_in_array(curr_centroid, centroids)):\n",
    "                        rand_idx = random.randint(-1,len(data)-1)\n",
    "                        curr_centroid = np.copy(data[rand_idx])\n",
    "                    centroids.append(curr_centroid)\n",
    "        else:\n",
    "            # self.init == 'manual'\n",
    "            centroids = self.init_val\n",
    "        \n",
    "        iteration = 1\n",
    "        is_convergen = False\n",
    "        \n",
    "        while (not is_convergen and iteration <= self.max_iter):\n",
    "            # calculate distance all data to all centroid\n",
    "            dist_matrix = self.__calculate_distance_matrix(data, centroids)\n",
    "            # assign all data to cluster\n",
    "            cluster_of_data = self.__assign_data_to_cluster(dist_matrix)\n",
    "            # get new possible centroid\n",
    "            new_centroids = self.__get_centroids(data, cluster_of_data, centroids)\n",
    "            # calculate distance all data to all new centroid\n",
    "            new_dist_matrix = self.__calculate_distance_matrix(data, new_centroids)\n",
    "            # assign all data to new cluster\n",
    "            new_cluster_of_data = self.__assign_data_to_cluster(new_dist_matrix)\n",
    "            # convergency checking\n",
    "            if (self.__calculate_error(data, cluster_of_data, new_cluster_of_data, centroids, new_centroids) >= 0):\n",
    "                is_convergen = True\n",
    "            \n",
    "            # for next iteration\n",
    "            if not is_convergen:\n",
    "                cluster_of_data = np.copy(new_cluster_of_data)\n",
    "                centroids = np.copy(new_centroids)\n",
    "                iteration += 1\n",
    "                \n",
    "        return np.array(cluster_of_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "\n",
    "Berikut ini merupakan hasil eksperimen implementasi KMedoid (PAM) untuk clustering data iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def purity(cluster_pred, label):\n",
    "    data_per_cluster = [[] for i in range(len(set(cluster_pred)))]\n",
    "    for i,x in enumerate(cluster_pred):\n",
    "        data_per_cluster[x].append(label[i])\n",
    "\n",
    "    sum = 0\n",
    "    for clust in data_per_cluster:\n",
    "        sum += stats.mode(clust)[1][0]\n",
    "\n",
    "    return sum/len(cluster_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "data = iris.data\n",
    "label = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering dengan k=4, randomize_cluster=0\n",
    "\n",
    "Pada percobaan ini, dipilih nilai k=4 dan randomize_cluster=0, artinya cluster yang akan dirandom centroidnya untuk setiap iterasi adalah cluster pertama. Hasil clustering dan *purity*-nya dapat dilihat pada *output* dari eksekusi *code*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Time taken: 0.005999326705932617 s ----\n",
      "Cluster prediction:\n",
      "[0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 3 3 0 3 3 0 3 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0\n",
      " 0 0 0 0 0 0 0 3 0 3 0 0 0 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 1 2 1 1 1 1 2 1 1 1 1\n",
      " 1 1 2 1 1 1 1 1 2 1 2 1 2 1 1 2 2 1 1 1 1 1 2 2 1 1 1 2 1 1 1 2 1 1 1 1 1\n",
      " 1 2]\n",
      "Purity: 0.8933333333333333\n"
     ]
    }
   ],
   "source": [
    "kmedoid = KMedoid(n_clusters=4, randomize_cluster=0)\n",
    "start = time.time()\n",
    "pred = kmedoid.fit_predict(data)\n",
    "\n",
    "print(\"---- Time taken: {} s ----\".format(time.time() - start))\n",
    "print(\"Cluster prediction:\")\n",
    "print(pred)\n",
    "print(\"Purity: {}\".format(purity(pred, label)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering dengan k=4, randomize_cluster=1\n",
    "\n",
    "Pada percobaan ini, dipilih nilai k=4 dan randomize_cluster=1, artinya cluster yang akan dirandom centroidnya untuk setiap iterasi adalah cluster kedua. Hasil clustering dan *purity*-nya dapat dilihat pada *output* dari eksekusi *code*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Time taken: 0.00672602653503418 s ----\n",
      "Cluster prediction:\n",
      "[1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1\n",
      " 1 0 1 1 0 0 1 1 0 1 0 1 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 3 2 3 2 2 2 2 3 3 3 2 2\n",
      " 3 2 3 2 2 2 2 2 3 2 3 2 3 2 2 3 3 2 3 3 2 2 3 3 2 2 2 3 2 2 2 3 2 2 2 3 2\n",
      " 2 2]\n",
      "Purity: 0.8733333333333333\n"
     ]
    }
   ],
   "source": [
    "kmedoid = KMedoid(n_clusters=4, randomize_cluster=1)\n",
    "start = time.time()\n",
    "pred = kmedoid.fit_predict(data)\n",
    "\n",
    "print(\"---- Time taken: {} s ----\".format(time.time() - start))\n",
    "print(\"Cluster prediction:\")\n",
    "print(pred)\n",
    "print(\"Purity: {}\".format(purity(pred, label)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering dengan k=4, randomize_cluster=2\n",
    "\n",
    "Pada percobaan ini, dipilih nilai k=4 dan randomize_cluster=2, artinya cluster yang akan dirandom centroidnya untuk setiap iterasi adalah cluster ketiga. Hasil clustering dan *purity*-nya dapat dilihat pada *output* dari eksekusi *code*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Time taken: 0.007439851760864258 s ----\n",
      "Cluster prediction:\n",
      "[2 2 2 2 2 2 1 2 2 2 2 2 2 1 1 2 1 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 1 2 2 2 2 2 2 2 3 3 3 0 3 0 3 0 3 0 0 0 0 0 0 3 0 0 0 0 3 0 3 0\n",
      " 0 3 3 3 0 0 0 0 0 3 0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 3 3 3 3 0 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3]\n",
      "Purity: 0.8933333333333333\n"
     ]
    }
   ],
   "source": [
    "kmedoid = KMedoid(n_clusters=4, randomize_cluster=2)\n",
    "start = time.time()\n",
    "pred = kmedoid.fit_predict(data)\n",
    "\n",
    "print(\"---- Time taken: {} s ----\".format(time.time() - start))\n",
    "print(\"Cluster prediction:\")\n",
    "print(pred)\n",
    "print(\"Purity: {}\".format(purity(pred, label)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering dengan k=4, randomize_cluster=3\n",
    "\n",
    "Pada percobaan ini, dipilih nilai k=4 dan randomize_cluster=0, artinya cluster yang akan dirandom centroidnya untuk setiap iterasi adalah cluster keempat. Hasil clustering dan *purity*-nya dapat dilihat pada *output* dari eksekusi *code*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Time taken: 0.019479751586914062 s ----\n",
      "Cluster prediction:\n",
      "[0 1 1 1 0 0 1 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 1 1 0 0 0 1 1 0\n",
      " 1 1 0 0 1 1 0 0 1 0 1 0 1 3 3 3 3 3 3 3 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 3 3 3 3 1 3 2 3 2 2 2 2 3 2 2 2 3\n",
      " 3 2 3 3 3 2 2 2 3 2 3 2 3 2 2 3 3 2 2 2 2 2 3 3 2 2 2 3 2 2 2 3 2 2 2 3 3\n",
      " 3 3]\n",
      "Purity: 0.8466666666666667\n"
     ]
    }
   ],
   "source": [
    "kmedoid = KMedoid(n_clusters=4, randomize_cluster=3)\n",
    "start = time.time()\n",
    "pred = kmedoid.fit_predict(data)\n",
    "\n",
    "print(\"---- Time taken: {} s ----\".format(time.time() - start))\n",
    "print(\"Cluster prediction:\")\n",
    "print(pred)\n",
    "print(\"Purity: {}\".format(purity(pred, label)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hasil dan Analisis\n",
    "\n",
    "Dari keempat eksperimen di atas, dapat ditarik kesimpulan bahwa untuk dataset iris, metode *KMeans (PAM)* dapat diterapkan untuk melakukan *clustering*. Pemilihan nilai randomize_cluster=0 dan randomize_cluster=2 menghasilkan *cluster* dengan *purity* tertinggi, yaitu 0.893. Keempat percobaan diatas menghasilkan *purity* yang berbeda meskipun nilai k sama, yaitu k=4. Hal ini dikarenakan inisiasi centroid yang random membuat hasil yang tidak sama serta pemilihan centroid mana yang akan di-random untuk setiap iterasinnya juga mempengaruhi hasil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
