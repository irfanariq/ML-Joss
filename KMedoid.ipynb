{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_iris().data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "\n",
    "class KMedoid:\n",
    "    \n",
    "    n_clusters = 2\n",
    "    init = 'random'\n",
    "    max_iter = 300\n",
    "    init_val = []\n",
    "    randomize_cluster = 0\n",
    "    choosen_cluster = []\n",
    "    \n",
    "    available_init = ['random', 'manual']\n",
    "    \n",
    "    def __init__(self, n_clusters=n_clusters, init=init, init_val=init_val, max_iter=max_iter, randomize_cluster=randomize_cluster):\n",
    "        if n_clusters <= 0:\n",
    "            raise Exception('n_clusters must be higher than 0')\n",
    "        if init not in self.available_init:\n",
    "            raise Exception('No init method \\'' + str(init) + '\\'. Available init methods'+ str(self.available_init))\n",
    "        if (init == 'manual' and len(init_val) != n_clusters):\n",
    "            raise Exception('init_val length doesn\\'t match with n_clusters '+ str(n_clusters))\n",
    "        if (n_clusters-1 < randomize_cluster) or (randomize_cluster < 0):\n",
    "            raise Exception('randomize_cluster must be between 0 and n_clusters-1')\n",
    "        self.n_clusters = n_clusters\n",
    "        self.init = init\n",
    "        self.max_iter = max_iter\n",
    "        self.init_val = init_val\n",
    "        self.randomize_cluster = randomize_cluster\n",
    "    \n",
    "    def __is_in_array(self, data, arr):\n",
    "        is_exist = False\n",
    "        arr_idx = 0\n",
    "        while (not is_exist and arr_idx < len(arr)):\n",
    "            is_data_equal = True\n",
    "            data_idx = 0\n",
    "            while (is_data_equal and data_idx < len(data)):\n",
    "                if (data[data_idx] != arr[arr_idx][data_idx]):\n",
    "                    is_data_equal = False\n",
    "                else:\n",
    "                    data_idx += 1\n",
    "            if is_data_equal:\n",
    "                is_exist = True\n",
    "            else:\n",
    "                arr_idx += 1\n",
    "        return is_exist\n",
    "        \n",
    "    def __manhattan_distance(self, data1, data2):\n",
    "        '''\n",
    "        Fungsi untuk menghitung manhattan distance di antara dua vector dengan panjang yang sama\n",
    "        '''\n",
    "        sum = 0\n",
    "        if (len(data1) == len(data2)):\n",
    "            for x1, x2 in zip(data1, data2):\n",
    "                sum += abs(x1 - x2)\n",
    "            return sum\n",
    "        else:\n",
    "            raise Exception('Length doesn\\'t match')\n",
    "            \n",
    "    def __get_distance(self, data1, data2):\n",
    "        return self.__manhattan_distance(data1, data2)\n",
    "        \n",
    "    def __calculate_distance_matrix(self, data, centroids):\n",
    "        dist_matrix = []        \n",
    "        for i in range(len(centroids)):\n",
    "            dist_curr_centroid = []\n",
    "            for j in range(len(data)):\n",
    "                dist = self.__get_distance(centroids[i], data[j])\n",
    "                dist_curr_centroid.append(dist)\n",
    "            dist_matrix.append(dist_curr_centroid)\n",
    "        \n",
    "        return dist_matrix\n",
    "    \n",
    "    def __assign_data_to_cluster(self, dist_matrix):\n",
    "        cluster_of_data = []\n",
    "        for j in range(len(dist_matrix[0])):\n",
    "            cluster = 0\n",
    "            min_distance = dist_matrix[0][j]\n",
    "            for i in range(1,len(dist_matrix)):\n",
    "                if (dist_matrix[i][j] < min_distance):\n",
    "                    cluster = i\n",
    "                    min_distance = dist_matrix[i][j]\n",
    "            cluster_of_data.append(cluster)\n",
    "        return cluster_of_data\n",
    "    \n",
    "    def __get_centroids(self, data, cluster_of_data, centroids):\n",
    "        # centroid candidate\n",
    "        data_of_randomize_cluster = []\n",
    "        for idx, data_cluster in enumerate(cluster_of_data):\n",
    "            if data_cluster == self.randomize_cluster:\n",
    "                data_of_randomize_cluster.append(data[idx])\n",
    "        \n",
    "        # choose random\n",
    "        idx = 0\n",
    "        stop = False\n",
    "        while ( not stop and idx < len(data_of_randomize_cluster)\n",
    "        ):\n",
    "            new_centroid = np.copy(data_of_randomize_cluster[idx])\n",
    "            if (\n",
    "                self.__get_distance(new_centroid, centroids[self.randomize_cluster]) == 0 or \n",
    "                self.__is_in_array(new_centroid, self.choosen_cluster)\n",
    "            ):\n",
    "                idx += 1\n",
    "            else:\n",
    "                stop = True\n",
    "        \n",
    "        if not self.__is_in_array(new_centroid, self.choosen_cluster):\n",
    "            self.choosen_cluster.append(new_centroid)\n",
    "        \n",
    "        new_centroids = np.copy(centroids)\n",
    "        new_centroids[self.randomize_cluster] = new_centroid\n",
    "        return new_centroids\n",
    "    \n",
    "    def __calculate_error(self, data, cluster_of_data, new_cluster_of_data, centroids, new_centroids):\n",
    "        old_error = 0\n",
    "        new_error = 0\n",
    "        for n in range(self.n_clusters):\n",
    "            for idx, val in enumerate(data):\n",
    "                old_error += self.__get_distance(val, centroids[cluster_of_data[idx]])\n",
    "                new_error += self.__get_distance(val, new_centroids[new_cluster_of_data[idx]])\n",
    "        \n",
    "        return new_error-old_error\n",
    "        \n",
    "    def fit_predict(self, data):\n",
    "        cluster_of_data = []\n",
    "        \n",
    "        # initiate centroid\n",
    "        centroids = []\n",
    "        if (self.init == 'random'):\n",
    "            # cek keunikan data\n",
    "            unique_data_idx = []\n",
    "            unique_data = []\n",
    "            i = 0\n",
    "            while (len(unique_data_idx) < self.n_clusters) and (i < len(data)):\n",
    "                if not self.__is_in_array(data[i], unique_data):\n",
    "                    unique_data_idx.append(i)\n",
    "                    unique_data.append(data[i])\n",
    "                i += 1\n",
    "                \n",
    "            if (len(unique_data_idx) < self.n_clusters):\n",
    "                # jika keunikan data kurang dari n_clusters\n",
    "                for u in unique_data_idx:\n",
    "                    curr_centroid = np.copy(data[u])\n",
    "                    centroids.append(curr_centroid)\n",
    "                for i in range(self.n_clusters - len(unique_data_idx)):\n",
    "                    rand_idx = random.randint(-1,len(data)-1)\n",
    "                    # cek apakah sudah terpilih atau belum\n",
    "                    while (rand_idx in unique_data_idx):\n",
    "                        rand_idx = random.randint(-1,len(data)-1)\n",
    "                    curr_centroid = np.copy(data[rand_idx])\n",
    "                    centroids.append(curr_centroid)\n",
    "            else:\n",
    "                for i in range(self.n_clusters):\n",
    "                    rand_idx = random.randint(-1,len(data)-1)\n",
    "                    curr_centroid = np.copy(data[rand_idx])\n",
    "                    # cek apakah sudah terpilih atau belum\n",
    "                    while (self.__is_in_array(curr_centroid, centroids)):\n",
    "                        rand_idx = random.randint(-1,len(data)-1)\n",
    "                        curr_centroid = np.copy(data[rand_idx])\n",
    "                    centroids.append(curr_centroid)\n",
    "        else:\n",
    "            # self.init == 'manual'\n",
    "            centroids = self.init_val\n",
    "        \n",
    "        iteration = 1\n",
    "        is_convergen = False\n",
    "        \n",
    "        while (not is_convergen and iteration <= self.max_iter):\n",
    "            # calculate distance all data to all centroid\n",
    "            dist_matrix = self.__calculate_distance_matrix(data, centroids)\n",
    "            # assign all data to cluster\n",
    "            cluster_of_data = self.__assign_data_to_cluster(dist_matrix)\n",
    "            # get new possible centroid\n",
    "            new_centroids = self.__get_centroids(data, cluster_of_data, centroids)\n",
    "            # calculate distance all data to all new centroid\n",
    "            new_dist_matrix = self.__calculate_distance_matrix(data, new_centroids)\n",
    "            # assign all data to new cluster\n",
    "            new_cluster_of_data = self.__assign_data_to_cluster(new_dist_matrix)\n",
    "            # convergency checking\n",
    "            if (self.__calculate_error(data, cluster_of_data, new_cluster_of_data, centroids, new_centroids) >= 0):\n",
    "                is_convergen = True\n",
    "            \n",
    "            # for next iteration\n",
    "            if not is_convergen:\n",
    "                cluster_of_data = np.copy(new_cluster_of_data)\n",
    "                centroids = np.copy(new_centroids)\n",
    "                iteration += 1\n",
    "                \n",
    "        return np.array(cluster_of_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 2, 2, 0, 1, 0, 0, 2, 2, 1, 3, 2, 2, 1, 1, 1, 0, 1, 0, 1, 0,\n",
       "       0, 0, 3, 2, 0, 0, 0, 2, 2, 1, 1, 1, 2, 0, 0, 2, 2, 0, 0, 2, 2, 0,\n",
       "       1, 2, 0, 2, 0, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmedoid = KMedoid(n_clusters=4)\n",
    "pred_a = kmedoid.fit_predict(data[:50])\n",
    "pred_a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
