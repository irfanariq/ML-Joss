{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN:\n",
    "    def __init__(self, \n",
    "                 layer_size= [50,1], \n",
    "                 lr= 0.001, \n",
    "                 momentum= 0, \n",
    "                 batch_size= None, \n",
    "                 init_seed = None, \n",
    "                 nb_epoch= 300):\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.layer_size = layer_size\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        self.velocity = []\n",
    "        self.velocity_bias = []\n",
    "        self.output_layer = []\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.nb_epoch = nb_epoch\n",
    "        \n",
    "        if init_seed != None:\n",
    "            np.random.seed(init_seed)\n",
    "            \n",
    "        for i, layer in enumerate(layer_size):\n",
    "            if i < (len(layer_size) - 1):\n",
    "                limit = np.sqrt(6 / (layer_size[i] + layer_size[i+1]))\n",
    "                self.weights.append(np.random.rand(layer_size[i], layer_size[i+1]) * 2 * limit - limit)\n",
    "                self.velocity.append(np.zeros((layer_size[i], layer_size[i+1])))\n",
    "            limit = np.sqrt(6 / (layer_size[i] + 1))\n",
    "            self.biases.append(np.random.rand(layer_size[i]) * 2 * limit - limit)\n",
    "            self.velocity_bias.append(np.zeros(layer_size[i]))\n",
    "        \n",
    "    def _sigmoid(self, x, derivative= False):\n",
    "        sigmoid =  1 / (1 + np.exp(-x))\n",
    "        if derivative:\n",
    "            return sigmoid * (1 - sigmoid)\n",
    "        else:\n",
    "            return sigmoid\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.x = np.array(x, dtype= np.float32)\n",
    "        self.y = np.array(y, dtype= np.float32)\n",
    "        if len(self.y.shape) == 1:\n",
    "            self.y = np.array([[y] for y in self.y], dtype= np.float32)\n",
    "        \n",
    "        limit = np.sqrt(6 / (self.x.shape[1] + self.layer_size[0]))\n",
    "        self.weights = [np.random.rand(self.x.shape[1], self.layer_size[0]) * limit * 2 - limit] + self.weights\n",
    "        self.velocity = [np.zeros((self.x.shape[1], self.layer_size[0]))] + self.velocity\n",
    "        if self.batch_size is None:\n",
    "            self.batch_size = self.x.shape[0]\n",
    "        \n",
    "        for i in range(self.nb_epoch):\n",
    "            loss = 0\n",
    "            indices = np.arange(self.y.shape[0])\n",
    "            np.random.shuffle(indices)            \n",
    "            self.x = self.x[indices]\n",
    "            self.y = self.y[indices]\n",
    "            \n",
    "            for idx in range(0, self.x.shape[0], self.batch_size):\n",
    "                data_in = self.x[idx : min(idx + self.batch_size, self.x.shape[0])]\n",
    "                data_target = self.y[idx : min(idx + self.batch_size, self.x.shape[0])]\n",
    "                out = self._feed_forward(data_in)\n",
    "                loss += np.sum(self._error(out, data_target))\n",
    "                self._backprop(data_in, data_target)\n",
    "            print(\"Epoch {}, loss: {}\".format(i, loss))\n",
    "    \n",
    "    def _feed_forward(self, input_data= []):\n",
    "        self.output_layer = []\n",
    "        in_layer = input_data\n",
    "        for weight, bias in zip(self.weights, self.biases):\n",
    "            out_layer = self._sigmoid(np.dot(in_layer, weight) + bias)\n",
    "            self.output_layer.append(out_layer)\n",
    "            \n",
    "            in_layer = out_layer\n",
    "        return out_layer\n",
    "        \n",
    "    def _error(self, pred, actual, derivative = False): \n",
    "        if derivative:\n",
    "            return (actual - pred) / (pred - (pred ** 2))\n",
    "        else :\n",
    "            return -(actual * np.log(pred) + ((1-actual) * np.log(1-pred)))\n",
    "    \n",
    "    def _backprop(self, data_in, data_target):\n",
    "        for i, w in reversed(list(enumerate(self.weights))):\n",
    "            if i == len(self.weights) - 1:\n",
    "                out_d = self._error(self.output_layer[i], data_target, derivative=True) * self._sigmoid(self.output_layer[i], derivative= True)\n",
    "                d_weight = self.lr * np.dot(self.output_layer[i - 1].T, out_d) + self.velocity[i] * self.momentum\n",
    "            elif i == 0:\n",
    "                out_d = np.dot(out_d, self.weights[i + 1].T) * self._sigmoid(self.output_layer[i], derivative= True)\n",
    "                d_weight = self.lr * np.dot(data_in.T, out_d) + self.velocity[i] * self.momentum\n",
    "            else:\n",
    "                out_d = np.dot(out_d, self.weights[i + 1].T) * self._sigmoid(self.output_layer[i], derivative= True)\n",
    "                d_weight = self.lr * np.dot(self.output_layer[i - 1].T, out_d) + self.velocity[i] * self.momentum\n",
    "#             print(out_d.shape)\n",
    "            d_bias = self.lr * np.sum(out_d, axis= 0) + self.velocity_bias[i] * self.momentum\n",
    "            \n",
    "            self.velocity_bias[i] = d_bias\n",
    "            self.velocity[i] = d_weight\n",
    "        \n",
    "        for i, w in enumerate(self.weights):\n",
    "#             print(\"updating layer {}\".format(i))\n",
    "            self.weights[i] += self.velocity[i]\n",
    "#             print(self.biases[i].shape)\n",
    "#             print(self.velocity_bias[i].shape)\n",
    "            self.biases[i] += self.velocity_bias[i]\n",
    "            \n",
    "    \n",
    "    def predict(self, data):\n",
    "        data = np.array(data, dtype= np.float32)\n",
    "        return self._feed_forward(data)\n",
    "    \n",
    "    def get_weights(self):\n",
    "        return self.weights\n",
    "    \n",
    "    def get_biases(self):\n",
    "        return self.biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1\n",
    "Data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss: 3.640343595735515\n",
      "Epoch 1, loss: 3.1185709434955973\n",
      "Epoch 2, loss: 2.88736671847234\n",
      "Epoch 3, loss: 2.7767926314669165\n",
      "Epoch 4, loss: 2.7895219367377666\n",
      "Epoch 5, loss: 2.8467273969890843\n",
      "Epoch 6, loss: 3.013042656913342\n",
      "Epoch 7, loss: 2.9026082732157237\n",
      "Epoch 8, loss: 2.993399730421239\n",
      "Epoch 9, loss: 2.9250136230586605\n",
      "Epoch 10, loss: 2.7726956199391273\n",
      "Epoch 11, loss: 2.7417409169192406\n",
      "Epoch 12, loss: 2.7453029276594947\n",
      "Epoch 13, loss: 2.7491350241058963\n",
      "Epoch 14, loss: 2.7482723520085433\n",
      "Epoch 15, loss: 2.740340697713246\n",
      "Epoch 16, loss: 2.7294832435819307\n",
      "Epoch 17, loss: 2.7186462237697895\n",
      "Epoch 18, loss: 2.710459988714808\n",
      "Epoch 19, loss: 2.764156596139263\n",
      "Epoch 20, loss: 2.6993432092181644\n",
      "Epoch 21, loss: 2.7540342349439855\n",
      "Epoch 22, loss: 2.6866429232731046\n",
      "Epoch 23, loss: 2.7833720350550326\n",
      "Epoch 24, loss: 2.767252426166668\n",
      "Epoch 25, loss: 2.7451865859598366\n",
      "Epoch 26, loss: 2.67262220269529\n",
      "Epoch 27, loss: 2.649020034259058\n",
      "Epoch 28, loss: 2.6320817775480263\n",
      "Epoch 29, loss: 2.620788487354145\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.49847481],\n",
       "       [0.50032081],\n",
       "       [0.62001194]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann = ANN(layer_size=[4, 4, 1], momentum= 0.9, lr= 0.05, batch_size=2, nb_epoch= 30)\n",
    "x = [[0,1], [0,0], [1,0], [1,1]]\n",
    "y = [[0], [0], [1], [1]]\n",
    "\n",
    "\n",
    "ann.fit(x, y)\n",
    "ann.predict([[0,0], [0,0.1], [10.1,0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2\n",
    "Data weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/irfanariq/.local/lib/python3.6/site-packages/sklearn/preprocessing/label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import arff\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Loading data\n",
    "data, meta = arff.loadarff('weather.arff')\n",
    "data_x = [list(d)[:4] for d in data]\n",
    "data_y = [[d[4]] for d in data]\n",
    "\n",
    "# encoding data\n",
    "le = LabelEncoder()\n",
    "data_y = le.fit_transform(data_y)\n",
    "\n",
    "ct = ColumnTransformer([('ohe', OneHotEncoder(), [0, 3]),], remainder= 'passthrough')\n",
    "data_x = ct.fit_transform(data_x)\n",
    "\n",
    "# splitting data into train and test data\n",
    "train_x, test_x, train_y, test_y = train_test_split(data_x, data_y, test_size= 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss: 12.059046394262744\n",
      "Epoch 1, loss: 11.68939150080578\n",
      "Epoch 2, loss: 10.378305546879062\n",
      "Epoch 3, loss: 10.07006945698248\n",
      "Epoch 4, loss: 9.838516836503121\n",
      "Epoch 5, loss: 9.681686196019818\n",
      "Epoch 6, loss: 9.505369454313882\n",
      "Epoch 7, loss: 9.399127625280794\n",
      "Epoch 8, loss: 9.269894069324353\n",
      "Epoch 9, loss: 9.143821571068832\n",
      "Epoch 10, loss: 9.069138242234938\n",
      "Epoch 11, loss: 8.955953909302638\n",
      "Epoch 12, loss: 8.88657223842729\n",
      "Epoch 13, loss: 8.838895805761455\n",
      "Epoch 14, loss: 8.76884030980719\n",
      "Epoch 15, loss: 8.71928608604832\n",
      "Epoch 16, loss: 8.63939516584853\n",
      "Epoch 17, loss: 8.61485338989728\n",
      "Epoch 18, loss: 8.561612256044578\n",
      "Epoch 19, loss: 8.524981995399504\n",
      "Epoch 20, loss: 8.503515754240041\n",
      "Epoch 21, loss: 8.470319659276749\n",
      "Epoch 22, loss: 8.439625005465995\n",
      "Epoch 23, loss: 8.413756578654064\n",
      "Epoch 24, loss: 8.389274275575543\n",
      "Epoch 25, loss: 8.386143754508057\n",
      "Epoch 26, loss: 8.353703186016338\n",
      "Epoch 27, loss: 8.342410127940393\n",
      "Epoch 28, loss: 8.31260869806666\n",
      "Epoch 29, loss: 8.327918371335196\n",
      "Prediction: [[0.65465461]\n",
      " [0.65465461]]\n",
      "Target: [1 1]\n"
     ]
    }
   ],
   "source": [
    "ann = ANN(layer_size=[3, 2, 1], momentum= 0.9, lr= 1e-3, nb_epoch= 30, batch_size=1)\n",
    "ann.fit(train_x, train_y)\n",
    "pred = ann.predict(test_x)\n",
    "\n",
    "print(\"Prediction: {}\".format(pred))\n",
    "print(\"Target: {}\".format(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
