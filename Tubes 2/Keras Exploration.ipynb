{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from scipy.io import arff\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, meta = arff.loadarff('weather.arff')\n",
    "data_x = [list(d)[:4] for d in data]\n",
    "data_y = [d[4] for d in data]\n",
    "\n",
    "le = LabelEncoder()\n",
    "data_y = le.fit_transform(data_y)\n",
    "\n",
    "ct = ColumnTransformer([('ohe', OneHotEncoder(), [0, 3]),], remainder= 'passthrough')\n",
    "data_x = ct.fit_transform(data_x)\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(data_x, data_y, test_size= 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_size = [50, 1]\n",
    "\n",
    "model = Sequential()\n",
    "for i, size in enumerate(dense_size):\n",
    "    if (i == 0):\n",
    "        model.add(Dense(size, input_dim= train_x.shape[1], activation= 'relu'))\n",
    "    elif (i != len(dense_size) -1 ):\n",
    "        model.add(Dense(size, activation= 'relu', kernel_initializer= 'glorot_uniform', bias_initializer= 'glorot_uniform'))\n",
    "    else:\n",
    "        model.add(Dense(size, activation= 'sigmoid', kernel_initializer= 'glorot_uniform', bias_initializer= 'glorot_uniform'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_67 (Dense)             (None, 50)                400       \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 451\n",
      "Trainable params: 451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/32\n",
      "12/12 [==============================] - 2s 130ms/step - loss: 2.4619 - acc: 0.5833\n",
      "Epoch 2/32\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.8621 - acc: 0.5833\n",
      "Epoch 3/32\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.8850 - acc: 0.5000\n",
      "Epoch 4/32\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.7295 - acc: 0.5000\n",
      "Epoch 5/32\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6469 - acc: 0.5833\n",
      "Epoch 6/32\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6314 - acc: 0.5833\n",
      "Epoch 7/32\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5675 - acc: 0.5833\n",
      "Epoch 8/32\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6219 - acc: 0.6667\n",
      "Epoch 9/32\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5556 - acc: 0.7500\n",
      "Epoch 10/32\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5418 - acc: 0.7500\n",
      "Epoch 11/32\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5343 - acc: 0.8333\n",
      "Epoch 12/32\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5437 - acc: 0.7500\n",
      "Epoch 13/32\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5282 - acc: 0.8333\n",
      "Epoch 14/32\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5314 - acc: 0.8333\n",
      "Epoch 15/32\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5530 - acc: 0.8333\n",
      "Epoch 16/32\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5098 - acc: 0.9167\n",
      "Epoch 17/32\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5126 - acc: 0.8333\n",
      "Epoch 18/32\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5021 - acc: 0.8333\n",
      "Epoch 19/32\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5123 - acc: 0.8333\n",
      "Epoch 20/32\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5382 - acc: 0.8333\n",
      "Epoch 21/32\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5411 - acc: 0.6667\n",
      "Epoch 22/32\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5461 - acc: 0.6667\n",
      "Epoch 23/32\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4981 - acc: 0.8333\n",
      "Epoch 24/32\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5055 - acc: 0.8333\n",
      "Epoch 25/32\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4831 - acc: 0.8333\n",
      "Epoch 26/32\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5144 - acc: 0.6667\n",
      "Epoch 27/32\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4802 - acc: 0.6667\n",
      "Epoch 28/32\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5261 - acc: 0.8333\n",
      "Epoch 29/32\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4731 - acc: 0.9167\n",
      "Epoch 30/32\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4817 - acc: 0.8333\n",
      "Epoch 31/32\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4908 - acc: 0.7500\n",
      "Epoch 32/32\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5434 - acc: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcb975dd128>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.fit(train_x, train_y, epochs= 32, batch_size= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 316ms/step\n",
      "\n",
      "acc: 100.00%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_x, test_y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.73346025],\n",
       "       [0.5150487 ]], dtype=float32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test_x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
